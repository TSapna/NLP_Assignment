{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Skipgram )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.21.5', '1.12.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#corpus is defined as a set of documents\n",
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \n",
    "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized  #we called each of this as \"tokens\", NOT words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numericalize\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.append('<UNK>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['<UNK>'] = 6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'animal',\n",
       " 1: 'dog',\n",
       " 2: 'banana',\n",
       " 3: 'cat',\n",
       " 4: 'apple',\n",
       " 5: 'fruit',\n",
       " 6: '<UNK>'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animal', 'dog', 'banana', 'cat', 'apple', 'fruit', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['banana', 'apple'],\n",
       " ['banana', 'fruit'],\n",
       " ['apple', 'banana'],\n",
       " ['apple', 'fruit'],\n",
       " ['fruit', 'banana'],\n",
       " ['fruit', 'apple'],\n",
       " ['cat', 'dog'],\n",
       " ['cat', 'animal'],\n",
       " ['dog', 'cat'],\n",
       " ['dog', 'animal'],\n",
       " ['animal', 'cat'],\n",
       " ['animal', 'dog']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgrams = []\n",
    "\n",
    "for sent in corpus_tokenized:\n",
    "    #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
    "    for i in range(1, len(sent) - 1): #start from 1 to second last\n",
    "        center_word = sent[i]\n",
    "        outside_words = [sent[i-1], sent[i+1]]  #window_size = 1\n",
    "        for o in outside_words:\n",
    "            skipgrams.append([center_word, o])\n",
    "\n",
    "skipgrams\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
    "        for i in range(1, len(sent) - 1): #start from 1 to second last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-1]], word2index[sent[i+1]]]  #window_size = 1\n",
    "            for o in outside_words:\n",
    "                skipgrams.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [4],\n",
      "       [2],\n",
      "       [5],\n",
      "       [5],\n",
      "       [2],\n",
      "       [1]])\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size = len(vocabs)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animal', 'dog', 'banana', 'cat', 'apple', 'fruit', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  \n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term) \n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) \n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing all_vocabs\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized)\n",
    "input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2 \n",
    "model = Skipgram(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0086, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 \n",
    "emb_size   = 2 \n",
    "model      = Skipgram(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 1.216724 | Time: ??\n",
      "Epoch 2000 | Loss: 0.534701 | Time: ??\n",
      "Epoch 3000 | Loss: 1.448289 | Time: ??\n",
      "Epoch 4000 | Loss: 1.004397 | Time: ??\n",
      "Epoch 5000 | Loss: 0.667942 | Time: ??\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, label_batch, all_vocabs)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: ??\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animal', 'dog', 'banana', 'cat', 'apple', 'fruit', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2310, -0.1218]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_center_embed = model.embedding_center_word(banana)\n",
    "banana_outisde_embed = model.embedding_outside_word(banana)\n",
    "\n",
    "banana_embed = (banana_center_embed + banana_outisde_embed) / 2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_center_word(word)\n",
    "    outside_embed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.397140979766846, 1.6728591918945312)\n",
      "(-4.982204437255859, -2.778129816055298)\n",
      "(-2.998368740081787, 4.093141555786133)\n"
     ]
    }
   ],
   "source": [
    "#find embedding of fruit, cat\n",
    "print(get_embed('fruit'))\n",
    "print(get_embed('cat'))\n",
    "\n",
    "print(get_embed('chaky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animal', 'dog', 'banana', 'cat', 'apple', 'fruit', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat          = get_embed('cat')\n",
    "fruit        = get_embed('fruit')\n",
    "animal       = get_embed('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  -0.9784242266496996\n",
      "cat vs. animal:  0.995228795221219\n",
      "cat vs. cat:  1.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "    \n",
    "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  -0.9784242266496996\n",
      "cat vs. animal:  0.995228795221219\n",
      "cat vs. cat:  1\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = 1 - spatial.distance.cosine(a, b)  \n",
    "    return cos_sim\n",
    "\n",
    "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
