{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading brown: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "corpus_sent = nltk.corpus.brown.sents(categories=['government'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'office', 'of', 'business', 'economics', '(', 'obe', ')', 'of', 'the', 'u.s.', 'department', 'of', 'commerce', 'provides', 'basic', 'measures', 'of', 'the', 'national', 'economy', 'and', 'current', 'analysis', 'of', 'short-run', 'changes', 'in', 'the', 'economic', 'situation', 'and', 'business', 'outlook', '.'], ['it', 'develops', 'and', 'analyzes', 'the', 'national', 'income', ',', 'balance', 'of', 'international', 'payments', ',', 'and', 'many', 'other', 'business', 'indicators', '.'], ['such', 'measures', 'are', 'essential', 'to', 'its', 'job', 'of', 'presenting', 'business', 'and', 'government', 'with', 'the', 'facts', 'required', 'to', 'meet', 'the', 'objective', 'of', 'expanding', 'business', 'and', 'improving', 'the', 'operation', 'of', 'the', 'economy', '.'], ['contact'], ['for', 'further', 'information', 'contact', 'director', ',', 'office', 'of', 'business', 'economics', ',', 'u.s.', 'department', 'of', 'commerce', ',', 'washington', '25', ',', 'd.c.', '.']]\n"
     ]
    }
   ],
   "source": [
    "corpus = [[word.lower() for word in sent] for sent in corpus_sent] #\n",
    "print(corpus[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3032"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus) #total sentences in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appeal', 'capacitance', 'aeronautics', 'subsequently', 'heat']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the unique words\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocab = list(set(flatten(corpus)))\n",
    "vocab[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4129\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# assigning id to the vocabs\n",
    "\n",
    "word2index = dict()\n",
    "word2index.update({\"<UNK>\":  0})\n",
    "\n",
    "for idx, v in enumerate(vocab):\n",
    "        word2index.update({v:  idx + 1})\n",
    "\n",
    "#adding <UNK> \n",
    "vocab.append('<UNK>') \n",
    "\n",
    "print(word2index['car'])\n",
    "\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "print(index2word[word2index['car']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#co-occurence matrix\n",
    "\n",
    "from collections import Counter\n",
    "X_i = Counter(flatten(corpus)) # X_i\n",
    "print(X_i['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining skipgram function with window size = 1\n",
    "\n",
    "def skip_grams_generated(window_size=1):\n",
    "\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1): # for changing the window size\n",
    "            target = sent[i]\n",
    "            \n",
    "            context = list()\n",
    "            \n",
    "            for j in range(window_size):\n",
    "                \n",
    "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
    "                    context.append(sent[i - (j + 1)])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
    "                    context.append(sent[i + (j + 1)])\n",
    "\n",
    "            for w in context:\n",
    "                skip_grams.append((target, w)) \n",
    "    \n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('office', 'the'): 14,\n",
       "         ('office', 'of'): 14,\n",
       "         ('office', 'business'): 2,\n",
       "         ('of', 'office'): 14,\n",
       "         ('of', 'business'): 26,\n",
       "         ('of', 'the'): 1900,\n",
       "         ('of', 'economics'): 2,\n",
       "         ('business', 'of'): 26,\n",
       "         ('business', 'economics'): 2,\n",
       "         ('business', 'office'): 2,\n",
       "         ('business', '('): 2,\n",
       "         ('economics', 'business'): 2,\n",
       "         ('economics', '('): 1,\n",
       "         ('economics', 'of'): 2,\n",
       "         ('economics', 'obe'): 1,\n",
       "         ('(', 'economics'): 1,\n",
       "         ('(', 'obe'): 1,\n",
       "         ('(', 'business'): 2,\n",
       "         ('(', ')'): 141,\n",
       "         ('obe', '('): 1,\n",
       "         ('obe', ')'): 1,\n",
       "         ('obe', 'economics'): 1,\n",
       "         ('obe', 'of'): 1,\n",
       "         (')', 'obe'): 1,\n",
       "         (')', 'of'): 32,\n",
       "         (')', '('): 129,\n",
       "         (')', 'the'): 30,\n",
       "         ('of', ')'): 33,\n",
       "         ('of', 'obe'): 1,\n",
       "         ('of', 'u.s.'): 10,\n",
       "         ('the', 'of'): 1804,\n",
       "         ('the', 'u.s.'): 9,\n",
       "         ('the', ')'): 30,\n",
       "         ('the', 'department'): 64,\n",
       "         ('u.s.', 'the'): 9,\n",
       "         ('u.s.', 'department'): 5,\n",
       "         ('u.s.', 'of'): 10,\n",
       "         ('department', 'u.s.'): 5,\n",
       "         ('department', 'of'): 68,\n",
       "         ('department', 'the'): 65,\n",
       "         ('department', 'commerce'): 4,\n",
       "         ('of', 'department'): 68,\n",
       "         ('of', 'commerce'): 13,\n",
       "         ('of', 'provides'): 1,\n",
       "         ('commerce', 'of'): 13,\n",
       "         ('commerce', 'provides'): 1,\n",
       "         ('commerce', 'department'): 4,\n",
       "         ('commerce', 'basic'): 1,\n",
       "         ('provides', 'commerce'): 1,\n",
       "         ('provides', 'basic'): 1,\n",
       "         ('provides', 'of'): 1,\n",
       "         ('provides', 'measures'): 1,\n",
       "         ('basic', 'provides'): 1,\n",
       "         ('basic', 'measures'): 1,\n",
       "         ('basic', 'commerce'): 1,\n",
       "         ('basic', 'of'): 9,\n",
       "         ('measures', 'basic'): 1,\n",
       "         ('measures', 'of'): 2,\n",
       "         ('measures', 'provides'): 1,\n",
       "         ('measures', 'the'): 1,\n",
       "         ('of', 'measures'): 2,\n",
       "         ('of', 'basic'): 9,\n",
       "         ('of', 'national'): 21,\n",
       "         ('the', 'national'): 30,\n",
       "         ('the', 'measures'): 1,\n",
       "         ('the', 'economy'): 11,\n",
       "         ('national', 'the'): 31,\n",
       "         ('national', 'economy'): 1,\n",
       "         ('national', 'of'): 21,\n",
       "         ('national', 'and'): 20,\n",
       "         ('economy', 'national'): 1,\n",
       "         ('economy', 'and'): 3,\n",
       "         ('economy', 'the'): 11,\n",
       "         ('economy', 'current'): 1,\n",
       "         ('and', 'economy'): 3,\n",
       "         ('and', 'current'): 6,\n",
       "         ('and', 'national'): 20,\n",
       "         ('and', 'analysis'): 2,\n",
       "         ('current', 'and'): 6,\n",
       "         ('current', 'analysis'): 1,\n",
       "         ('current', 'economy'): 1,\n",
       "         ('current', 'of'): 10,\n",
       "         ('analysis', 'current'): 1,\n",
       "         ('analysis', 'of'): 5,\n",
       "         ('analysis', 'and'): 2,\n",
       "         ('analysis', 'short-run'): 1,\n",
       "         ('of', 'analysis'): 5,\n",
       "         ('of', 'short-run'): 1,\n",
       "         ('of', 'current'): 10,\n",
       "         ('of', 'changes'): 4,\n",
       "         ('short-run', 'of'): 1,\n",
       "         ('short-run', 'changes'): 1,\n",
       "         ('short-run', 'analysis'): 1,\n",
       "         ('short-run', 'in'): 1,\n",
       "         ('changes', 'short-run'): 1,\n",
       "         ('changes', 'in'): 6,\n",
       "         ('changes', 'of'): 4,\n",
       "         ('changes', 'the'): 5,\n",
       "         ('in', 'changes'): 6,\n",
       "         ('in', 'the'): 438,\n",
       "         ('in', 'short-run'): 1,\n",
       "         ('in', 'economic'): 2,\n",
       "         ('the', 'in'): 466,\n",
       "         ('the', 'economic'): 3,\n",
       "         ('the', 'changes'): 5,\n",
       "         ('the', 'situation'): 7,\n",
       "         ('economic', 'the'): 3,\n",
       "         ('economic', 'situation'): 1,\n",
       "         ('economic', 'in'): 2,\n",
       "         ('economic', 'and'): 10,\n",
       "         ('situation', 'economic'): 1,\n",
       "         ('situation', 'and'): 1,\n",
       "         ('situation', 'the'): 7,\n",
       "         ('situation', 'business'): 1,\n",
       "         ('and', 'situation'): 1,\n",
       "         ('and', 'business'): 20,\n",
       "         ('and', 'economic'): 10,\n",
       "         ('and', 'outlook'): 1,\n",
       "         ('business', 'and'): 21,\n",
       "         ('business', 'outlook'): 2,\n",
       "         ('business', 'situation'): 1,\n",
       "         ('business', '.'): 17,\n",
       "         ('outlook', 'business'): 2,\n",
       "         ('outlook', '.'): 2,\n",
       "         ('outlook', 'and'): 1,\n",
       "         ('develops', 'it'): 1,\n",
       "         ('develops', 'and'): 1,\n",
       "         ('develops', 'analyzes'): 1,\n",
       "         ('and', 'develops'): 1,\n",
       "         ('and', 'analyzes'): 1,\n",
       "         ('and', 'it'): 14,\n",
       "         ('and', 'the'): 364,\n",
       "         ('analyzes', 'and'): 1,\n",
       "         ('analyzes', 'the'): 1,\n",
       "         ('analyzes', 'develops'): 1,\n",
       "         ('analyzes', 'national'): 1,\n",
       "         ('the', 'analyzes'): 1,\n",
       "         ('the', 'and'): 362,\n",
       "         ('the', 'income'): 12,\n",
       "         ('national', 'income'): 1,\n",
       "         ('national', 'analyzes'): 1,\n",
       "         ('national', ','): 10,\n",
       "         ('income', 'national'): 1,\n",
       "         ('income', ','): 4,\n",
       "         ('income', 'the'): 12,\n",
       "         ('income', 'balance'): 1,\n",
       "         (',', 'income'): 4,\n",
       "         (',', 'balance'): 2,\n",
       "         (',', 'national'): 11,\n",
       "         (',', 'of'): 275,\n",
       "         ('balance', ','): 2,\n",
       "         ('balance', 'of'): 5,\n",
       "         ('balance', 'income'): 1,\n",
       "         ('balance', 'international'): 1,\n",
       "         ('of', 'balance'): 5,\n",
       "         ('of', 'international'): 8,\n",
       "         ('of', ','): 274,\n",
       "         ('of', 'payments'): 9,\n",
       "         ('international', 'of'): 8,\n",
       "         ('international', 'payments'): 1,\n",
       "         ('international', 'balance'): 1,\n",
       "         ('international', ','): 11,\n",
       "         ('payments', 'international'): 1,\n",
       "         ('payments', ','): 4,\n",
       "         ('payments', 'of'): 9,\n",
       "         ('payments', 'and'): 5,\n",
       "         (',', 'payments'): 4,\n",
       "         (',', 'and'): 632,\n",
       "         (',', 'international'): 11,\n",
       "         (',', 'many'): 20,\n",
       "         ('and', ','): 616,\n",
       "         ('and', 'many'): 7,\n",
       "         ('and', 'payments'): 5,\n",
       "         ('and', 'other'): 55,\n",
       "         ('many', 'and'): 7,\n",
       "         ('many', 'other'): 6,\n",
       "         ('many', ','): 20,\n",
       "         ('many', 'business'): 1,\n",
       "         ('other', 'many'): 6,\n",
       "         ('other', 'business'): 1,\n",
       "         ('other', 'and'): 56,\n",
       "         ('other', 'indicators'): 1,\n",
       "         ('business', 'other'): 1,\n",
       "         ('business', 'indicators'): 1,\n",
       "         ('business', 'many'): 1,\n",
       "         ('indicators', 'business'): 1,\n",
       "         ('indicators', '.'): 1,\n",
       "         ('indicators', 'other'): 1,\n",
       "         ('measures', 'such'): 2,\n",
       "         ('measures', 'are'): 2,\n",
       "         ('measures', 'essential'): 1,\n",
       "         ('are', 'measures'): 2,\n",
       "         ('are', 'essential'): 4,\n",
       "         ('are', 'such'): 9,\n",
       "         ('are', 'to'): 55,\n",
       "         ('essential', 'are'): 4,\n",
       "         ('essential', 'to'): 4,\n",
       "         ('essential', 'measures'): 1,\n",
       "         ('essential', 'its'): 1,\n",
       "         ('to', 'essential'): 4,\n",
       "         ('to', 'its'): 21,\n",
       "         ('to', 'are'): 55,\n",
       "         ('to', 'job'): 2,\n",
       "         ('its', 'to'): 21,\n",
       "         ('its', 'job'): 1,\n",
       "         ('its', 'essential'): 1,\n",
       "         ('its', 'of'): 30,\n",
       "         ('job', 'its'): 1,\n",
       "         ('job', 'of'): 2,\n",
       "         ('job', 'to'): 2,\n",
       "         ('job', 'presenting'): 1,\n",
       "         ('of', 'job'): 2,\n",
       "         ('of', 'presenting'): 1,\n",
       "         ('of', 'its'): 30,\n",
       "         ('presenting', 'of'): 1,\n",
       "         ('presenting', 'business'): 1,\n",
       "         ('presenting', 'job'): 1,\n",
       "         ('presenting', 'and'): 1,\n",
       "         ('business', 'presenting'): 1,\n",
       "         ('business', 'government'): 2,\n",
       "         ('and', 'government'): 9,\n",
       "         ('and', 'presenting'): 1,\n",
       "         ('and', 'with'): 31,\n",
       "         ('government', 'and'): 9,\n",
       "         ('government', 'with'): 4,\n",
       "         ('government', 'business'): 2,\n",
       "         ('government', 'the'): 99,\n",
       "         ('with', 'government'): 4,\n",
       "         ('with', 'the'): 112,\n",
       "         ('with', 'and'): 30,\n",
       "         ('with', 'facts'): 1,\n",
       "         ('the', 'with'): 115,\n",
       "         ('the', 'facts'): 6,\n",
       "         ('the', 'government'): 88,\n",
       "         ('the', 'required'): 7,\n",
       "         ('facts', 'the'): 6,\n",
       "         ('facts', 'required'): 1,\n",
       "         ('facts', 'with'): 1,\n",
       "         ('facts', 'to'): 1,\n",
       "         ('required', 'facts'): 1,\n",
       "         ('required', 'to'): 19,\n",
       "         ('required', 'the'): 7,\n",
       "         ('required', 'meet'): 1,\n",
       "         ('to', 'required'): 19,\n",
       "         ('to', 'meet'): 11,\n",
       "         ('to', 'facts'): 1,\n",
       "         ('to', 'the'): 568,\n",
       "         ('meet', 'to'): 12,\n",
       "         ('meet', 'the'): 5,\n",
       "         ('meet', 'required'): 1,\n",
       "         ('meet', 'objective'): 1,\n",
       "         ('the', 'meet'): 5,\n",
       "         ('the', 'objective'): 6,\n",
       "         ('the', 'to'): 571,\n",
       "         ('objective', 'the'): 12,\n",
       "         ('objective', 'of'): 7,\n",
       "         ('objective', 'meet'): 1,\n",
       "         ('objective', 'expanding'): 1,\n",
       "         ('of', 'objective'): 7,\n",
       "         ('of', 'expanding'): 1,\n",
       "         ('expanding', 'of'): 1,\n",
       "         ('expanding', 'business'): 1,\n",
       "         ('expanding', 'objective'): 1,\n",
       "         ('expanding', 'and'): 1,\n",
       "         ('business', 'expanding'): 1,\n",
       "         ('business', 'improving'): 1,\n",
       "         ('and', 'improving'): 1,\n",
       "         ('and', 'expanding'): 1,\n",
       "         ('improving', 'and'): 1,\n",
       "         ('improving', 'the'): 3,\n",
       "         ('improving', 'business'): 1,\n",
       "         ('improving', 'operation'): 1,\n",
       "         ('the', 'improving'): 3,\n",
       "         ('the', 'operation'): 15,\n",
       "         ('operation', 'the'): 15,\n",
       "         ('operation', 'of'): 9,\n",
       "         ('operation', 'improving'): 1,\n",
       "         ('of', 'operation'): 9,\n",
       "         ('of', 'economy'): 7,\n",
       "         ('the', '.'): 176,\n",
       "         ('economy', '.'): 3,\n",
       "         ('economy', 'of'): 7,\n",
       "         ('further', 'for'): 7,\n",
       "         ('further', 'information'): 4,\n",
       "         ('further', 'contact'): 1,\n",
       "         ('information', 'further'): 4,\n",
       "         ('information', 'contact'): 4,\n",
       "         ('information', 'for'): 7,\n",
       "         ('information', 'director'): 1,\n",
       "         ('contact', 'information'): 4,\n",
       "         ('contact', 'director'): 1,\n",
       "         ('contact', 'further'): 1,\n",
       "         ('contact', ','): 4,\n",
       "         ('director', 'contact'): 1,\n",
       "         ('director', ','): 6,\n",
       "         ('director', 'information'): 1,\n",
       "         ('director', 'office'): 1,\n",
       "         (',', 'director'): 6,\n",
       "         (',', 'office'): 8,\n",
       "         (',', 'contact'): 4,\n",
       "         ('office', ','): 8,\n",
       "         ('office', 'director'): 1,\n",
       "         ('business', ','): 28,\n",
       "         ('economics', ','): 2,\n",
       "         ('economics', 'u.s.'): 1,\n",
       "         (',', 'economics'): 2,\n",
       "         (',', 'u.s.'): 17,\n",
       "         (',', 'business'): 28,\n",
       "         (',', 'department'): 17,\n",
       "         ('u.s.', ','): 16,\n",
       "         ('u.s.', 'economics'): 1,\n",
       "         ('department', ','): 17,\n",
       "         ('commerce', ','): 8,\n",
       "         ('commerce', 'washington'): 1,\n",
       "         (',', 'commerce'): 8,\n",
       "         (',', 'washington'): 32,\n",
       "         (',', '25'): 25,\n",
       "         ('washington', ','): 32,\n",
       "         ('washington', '25'): 9,\n",
       "         ('washington', 'commerce'): 1,\n",
       "         ('25', 'washington'): 9,\n",
       "         ('25', ','): 25,\n",
       "         ('25', 'd.c.'): 9,\n",
       "         (',', 'd.c.'): 16,\n",
       "         (',', '.'): 42,\n",
       "         ('d.c.', ','): 16,\n",
       "         ('d.c.', '.'): 7,\n",
       "         ('d.c.', '25'): 9,\n",
       "         ('information', 'economic'): 1,\n",
       "         ('information', 'is'): 2,\n",
       "         ('information', 'made'): 1,\n",
       "         ('is', 'information'): 2,\n",
       "         ('is', 'made'): 7,\n",
       "         ('is', 'economic'): 2,\n",
       "         ('is', 'available'): 5,\n",
       "         ('made', 'is'): 7,\n",
       "         ('made', 'available'): 5,\n",
       "         ('made', 'information'): 1,\n",
       "         ('made', 'to'): 39,\n",
       "         ('available', 'made'): 5,\n",
       "         ('available', 'to'): 14,\n",
       "         ('available', 'is'): 5,\n",
       "         ('available', 'businessmen'): 1,\n",
       "         ('to', 'available'): 14,\n",
       "         ('to', 'businessmen'): 1,\n",
       "         ('to', 'made'): 39,\n",
       "         ('to', 'and'): 119,\n",
       "         ('businessmen', 'to'): 1,\n",
       "         ('businessmen', 'and'): 2,\n",
       "         ('businessmen', 'available'): 1,\n",
       "         ('businessmen', 'economists'): 1,\n",
       "         ('and', 'businessmen'): 2,\n",
       "         ('and', 'economists'): 2,\n",
       "         ('and', 'to'): 118,\n",
       "         ('and', 'promptly'): 1,\n",
       "         ('economists', 'and'): 2,\n",
       "         ('economists', 'promptly'): 1,\n",
       "         ('economists', 'businessmen'): 1,\n",
       "         ('economists', 'through'): 1,\n",
       "         ('promptly', 'economists'): 1,\n",
       "         ('promptly', 'through'): 1,\n",
       "         ('promptly', 'and'): 1,\n",
       "         ('promptly', 'the'): 1,\n",
       "         ('through', 'promptly'): 1,\n",
       "         ('through', 'the'): 22,\n",
       "         ('through', 'economists'): 1,\n",
       "         ('through', 'monthly'): 1,\n",
       "         ('the', 'through'): 24,\n",
       "         ('the', 'monthly'): 1,\n",
       "         ('the', 'promptly'): 1,\n",
       "         ('the', 'survey'): 1,\n",
       "         ('monthly', 'the'): 1,\n",
       "         ('monthly', 'survey'): 1,\n",
       "         ('monthly', 'through'): 1,\n",
       "         ('monthly', 'of'): 1,\n",
       "         ('survey', 'monthly'): 1,\n",
       "         ('survey', 'of'): 2,\n",
       "         ('survey', 'the'): 1,\n",
       "         ('survey', 'current'): 1,\n",
       "         ('of', 'survey'): 2,\n",
       "         ('of', 'monthly'): 1,\n",
       "         ('current', 'business'): 1,\n",
       "         ('current', 'survey'): 1,\n",
       "         ('business', 'current'): 1,\n",
       "         ('business', 'its'): 1,\n",
       "         ('and', 'its'): 17,\n",
       "         ('and', 'weekly'): 1,\n",
       "         ('its', 'and'): 17,\n",
       "         ('its', 'weekly'): 1,\n",
       "         ('its', 'business'): 1,\n",
       "         ('its', 'supplement'): 1,\n",
       "         ('weekly', 'its'): 1,\n",
       "         ('weekly', 'supplement'): 1,\n",
       "         ('weekly', 'and'): 1,\n",
       "         ('weekly', '.'): 2,\n",
       "         ('supplement', 'weekly'): 1,\n",
       "         ('supplement', '.'): 1,\n",
       "         ('supplement', 'its'): 2,\n",
       "         ('periodical', 'this'): 1,\n",
       "         ('periodical', ','): 2,\n",
       "         ('periodical', 'including'): 1,\n",
       "         (',', 'periodical'): 2,\n",
       "         (',', 'including'): 21,\n",
       "         (',', 'this'): 88,\n",
       "         (',', 'weekly'): 1,\n",
       "         ('including', ','): 21,\n",
       "         ('including', 'weekly'): 1,\n",
       "         ('including', 'periodical'): 1,\n",
       "         ('including', 'statistical'): 1,\n",
       "         ('weekly', 'including'): 1,\n",
       "         ('weekly', 'statistical'): 1,\n",
       "         ('weekly', ','): 1,\n",
       "         ('weekly', 'supplements'): 1,\n",
       "         ('statistical', 'weekly'): 1,\n",
       "         ('statistical', 'supplements'): 1,\n",
       "         ('statistical', 'including'): 1,\n",
       "         ('statistical', ','): 1,\n",
       "         ('supplements', 'statistical'): 1,\n",
       "         ('supplements', ','): 1,\n",
       "         ('supplements', 'weekly'): 1,\n",
       "         ('supplements', 'is'): 1,\n",
       "         (',', 'supplements'): 1,\n",
       "         (',', 'is'): 93,\n",
       "         (',', 'statistical'): 1,\n",
       "         (',', 'available'): 8,\n",
       "         ('is', ','): 93,\n",
       "         ('is', 'supplements'): 1,\n",
       "         ('is', 'for'): 23,\n",
       "         ('available', 'for'): 10,\n",
       "         ('available', ','): 7,\n",
       "         ('available', '$4'): 1,\n",
       "         ('for', 'available'): 10,\n",
       "         ('for', '$4'): 2,\n",
       "         ('for', 'is'): 22,\n",
       "         ('for', 'per'): 4,\n",
       "         ('$4', 'for'): 2,\n",
       "         ('$4', 'per'): 1,\n",
       "         ('$4', 'available'): 1,\n",
       "         ('$4', 'year'): 1,\n",
       "         ('per', '$4'): 1,\n",
       "         ('per', 'year'): 6,\n",
       "         ('per', 'for'): 4,\n",
       "         ('per', 'from'): 1,\n",
       "         ('year', 'per'): 6,\n",
       "         ('year', 'from'): 1,\n",
       "         ('year', '$4'): 1,\n",
       "         ('year', 'commerce'): 1,\n",
       "         ('from', 'year'): 1,\n",
       "         ('from', 'commerce'): 1,\n",
       "         ('from', 'per'): 1,\n",
       "         ('from', 'field'): 1,\n",
       "         ('commerce', 'from'): 1,\n",
       "         ('commerce', 'field'): 1,\n",
       "         ('commerce', 'year'): 1,\n",
       "         ('commerce', 'offices'): 1,\n",
       "         ('field', 'commerce'): 1,\n",
       "         ('field', 'offices'): 1,\n",
       "         ('field', 'from'): 1,\n",
       "         ('field', 'or'): 1,\n",
       "         ('offices', 'field'): 1,\n",
       "         ('offices', 'or'): 1,\n",
       "         ('offices', 'commerce'): 1,\n",
       "         ('offices', 'superintendent'): 1,\n",
       "         ('or', 'offices'): 1,\n",
       "         ('or', 'superintendent'): 1,\n",
       "         ('or', 'field'): 1,\n",
       "         ('or', 'of'): 41,\n",
       "         ('superintendent', 'or'): 1,\n",
       "         ('superintendent', 'of'): 3,\n",
       "         ('superintendent', 'offices'): 1,\n",
       "         ('superintendent', 'documents'): 2,\n",
       "         ('of', 'superintendent'): 3,\n",
       "         ('of', 'documents'): 3,\n",
       "         ('of', 'or'): 41,\n",
       "         ('documents', 'of'): 3,\n",
       "         ('documents', ','): 3,\n",
       "         ('documents', 'superintendent'): 2,\n",
       "         ('documents', 'u.s.'): 2,\n",
       "         (',', 'documents'): 3,\n",
       "         (',', 'government'): 12,\n",
       "         ('u.s.', 'government'): 3,\n",
       "         ('u.s.', 'documents'): 2,\n",
       "         ('u.s.', 'printing'): 2,\n",
       "         ('government', 'u.s.'): 4,\n",
       "         ('government', 'printing'): 2,\n",
       "         ('government', ','): 12,\n",
       "         ('government', 'office'): 2,\n",
       "         ('printing', 'government'): 2,\n",
       "         ('printing', 'office'): 2,\n",
       "         ('printing', 'u.s.'): 2,\n",
       "         ('printing', ','): 5,\n",
       "         ('office', 'printing'): 2,\n",
       "         ('office', 'government'): 2,\n",
       "         ('office', 'washington'): 2,\n",
       "         (',', 'printing'): 5,\n",
       "         ('washington', 'office'): 2,\n",
       "         ('assistance', 'technical'): 4,\n",
       "         ('assistance', 'to'): 7,\n",
       "         ('assistance', 'small'): 1,\n",
       "         ('to', 'assistance'): 7,\n",
       "         ('to', 'small'): 14,\n",
       "         ('to', 'technical'): 3,\n",
       "         ('to', 'business'): 9,\n",
       "         ('small', 'to'): 15,\n",
       "         ('small', 'business'): 36,\n",
       "         ('small', 'assistance'): 1,\n",
       "         ('small', 'community'): 1,\n",
       "         ('business', 'small'): 37,\n",
       "         ('business', 'community'): 2,\n",
       "         ('business', 'to'): 8,\n",
       "         ('small', 'the'): 13,\n",
       "         ('small', 'administration'): 7,\n",
       "         ('business', 'administration'): 9,\n",
       "         ('business', 'the'): 26,\n",
       "         ('administration', 'business'): 9,\n",
       "         ('administration', '('): 1,\n",
       "         ('administration', 'small'): 9,\n",
       "         ('administration', 'sba'): 1,\n",
       "         ('(', 'administration'): 1,\n",
       "         ('(', 'sba'): 1,\n",
       "         ('sba', '('): 1,\n",
       "         ('sba', ')'): 1,\n",
       "         ('sba', 'administration'): 1,\n",
       "         ('sba', 'provides'): 1,\n",
       "         (')', 'sba'): 1,\n",
       "         (')', 'provides'): 1,\n",
       "         (')', 'guidance'): 1,\n",
       "         ('provides', ')'): 1,\n",
       "         ('provides', 'guidance'): 1,\n",
       "         ('provides', 'sba'): 1,\n",
       "         ('provides', 'and'): 2,\n",
       "         ('guidance', 'provides'): 1,\n",
       "         ('guidance', 'and'): 2,\n",
       "         ('guidance', ')'): 1,\n",
       "         ('guidance', 'advice'): 1,\n",
       "         ('and', 'guidance'): 3,\n",
       "         ('and', 'advice'): 2,\n",
       "         ('and', 'provides'): 2,\n",
       "         ('and', 'on'): 28,\n",
       "         ('advice', 'and'): 2,\n",
       "         ('advice', 'on'): 2,\n",
       "         ('advice', 'guidance'): 2,\n",
       "         ('advice', 'sources'): 1,\n",
       "         ('on', 'advice'): 2,\n",
       "         ('on', 'sources'): 4,\n",
       "         ('on', 'and'): 30,\n",
       "         ('on', 'of'): 39,\n",
       "         ('sources', 'on'): 4,\n",
       "         ('sources', 'of'): 8,\n",
       "         ('sources', 'advice'): 1,\n",
       "         ('sources', 'technical'): 1,\n",
       "         ('of', 'sources'): 8,\n",
       "         ('of', 'technical'): 3,\n",
       "         ('of', 'on'): 40,\n",
       "         ('of', 'information'): 9,\n",
       "         ('technical', 'of'): 3,\n",
       "         ('technical', 'information'): 2,\n",
       "         ('technical', 'sources'): 1,\n",
       "         ('technical', 'relating'): 1,\n",
       "         ('information', 'technical'): 2,\n",
       "         ('information', 'relating'): 2,\n",
       "         ('information', 'of'): 9,\n",
       "         ('information', 'to'): 7,\n",
       "         ('relating', 'information'): 2,\n",
       "         ('relating', 'to'): 8,\n",
       "         ('relating', 'technical'): 1,\n",
       "         ('relating', 'small'): 1,\n",
       "         ('to', 'relating'): 8,\n",
       "         ('to', 'information'): 7,\n",
       "         ('small', 'relating'): 1,\n",
       "         ('small', 'management'): 1,\n",
       "         ('business', 'management'): 4,\n",
       "         ('management', 'business'): 3,\n",
       "         ('management', 'and'): 12,\n",
       "         ('management', 'small'): 1,\n",
       "         ('management', 'research'): 1,\n",
       "         ('and', 'management'): 12,\n",
       "         ('and', 'research'): 32,\n",
       "         ('and', 'and'): 50,\n",
       "         ('research', 'and'): 29,\n",
       "         ('research', 'management'): 1,\n",
       "         ('research', 'development'): 12,\n",
       "         ('and', 'development'): 42,\n",
       "         ('and', 'of'): 268,\n",
       "         ('development', 'and'): 40,\n",
       "         ('development', 'of'): 45,\n",
       "         ('development', 'research'): 14,\n",
       "         ('development', 'products'): 1,\n",
       "         ('of', 'development'): 45,\n",
       "         ('of', 'products'): 7,\n",
       "         ('of', 'and'): 269,\n",
       "         ('of', '.'): 132,\n",
       "         ('products', 'of'): 7,\n",
       "         ('products', '.'): 4,\n",
       "         ('products', 'development'): 1,\n",
       "         ('management', 'practical'): 1,\n",
       "         ('management', 'problems'): 1,\n",
       "         ('problems', 'management'): 1,\n",
       "         ('problems', 'and'): 6,\n",
       "         ('problems', 'practical'): 1,\n",
       "         ('problems', 'their'): 2,\n",
       "         ('and', 'problems'): 6,\n",
       "         ('and', 'their'): 21,\n",
       "         ('and', 'suggested'): 1,\n",
       "         ('their', 'and'): 22,\n",
       "         ('their', 'suggested'): 1,\n",
       "         ('their', 'problems'): 2,\n",
       "         ('their', 'solutions'): 1,\n",
       "         ('suggested', 'their'): 1,\n",
       "         ('suggested', 'solutions'): 1,\n",
       "         ('suggested', 'and'): 1,\n",
       "         ('suggested', 'are'): 1,\n",
       "         ('solutions', 'suggested'): 1,\n",
       "         ('solutions', 'are'): 1,\n",
       "         ('solutions', 'their'): 1,\n",
       "         ('solutions', 'dealt'): 1,\n",
       "         ('are', 'solutions'): 1,\n",
       "         ('are', 'dealt'): 1,\n",
       "         ('are', 'suggested'): 1,\n",
       "         ('are', 'with'): 5,\n",
       "         ('dealt', 'are'): 1,\n",
       "         ('dealt', 'with'): 2,\n",
       "         ('dealt', 'solutions'): 1,\n",
       "         ('dealt', 'in'): 1,\n",
       "         ('with', 'dealt'): 2,\n",
       "         ('with', 'in'): 35,\n",
       "         ('with', 'are'): 5,\n",
       "         ('with', 'a'): 26,\n",
       "         ('in', 'with'): 29,\n",
       "         ('in', 'a'): 65,\n",
       "         ('in', 'dealt'): 1,\n",
       "         ('in', 'series'): 2,\n",
       "         ('a', 'in'): 69,\n",
       "         ('a', 'series'): 7,\n",
       "         ('a', 'with'): 27,\n",
       "         ('a', 'of'): 226,\n",
       "         ('series', 'a'): 7,\n",
       "         ('series', 'of'): 8,\n",
       "         ('series', 'in'): 2,\n",
       "         ('series', 'sba'): 1,\n",
       "         ('of', 'series'): 8,\n",
       "         ('of', 'sba'): 1,\n",
       "         ('of', 'a'): 234,\n",
       "         ('of', 'publications'): 3,\n",
       "         ('sba', 'of'): 1,\n",
       "         ('sba', 'publications'): 1,\n",
       "         ('sba', 'series'): 1,\n",
       "         ('sba', '.'): 2,\n",
       "         ('publications', 'sba'): 1,\n",
       "         ('publications', '.'): 5,\n",
       "         ('publications', 'of'): 3,\n",
       "         ('publications', 'these'): 3,\n",
       "         ('publications', ','): 2,\n",
       "         ('publications', 'written'): 1,\n",
       "         (',', 'publications'): 2,\n",
       "         (',', 'written'): 1,\n",
       "         (',', 'these'): 30,\n",
       "         (',', 'especially'): 3,\n",
       "         ('written', ','): 1,\n",
       "         ('written', 'especially'): 1,\n",
       "         ('written', 'publications'): 1,\n",
       "         ('written', 'for'): 1,\n",
       "         ('especially', 'written'): 1,\n",
       "         ('especially', 'for'): 2,\n",
       "         ('especially', ','): 3,\n",
       "         ('especially', 'the'): 1,\n",
       "         ('for', 'especially'): 2,\n",
       "         ('for', 'the'): 261,\n",
       "         ('for', 'written'): 1,\n",
       "         ('for', 'managers'): 1,\n",
       "         ('the', 'for'): 262,\n",
       "         ('the', 'managers'): 1,\n",
       "         ('the', 'especially'): 1,\n",
       "         ('the', 'or'): 66,\n",
       "         ('managers', 'the'): 1,\n",
       "         ('managers', 'or'): 1,\n",
       "         ('managers', 'for'): 1,\n",
       "         ('managers', 'owners'): 1,\n",
       "         ('or', 'managers'): 1,\n",
       "         ('or', 'owners'): 1,\n",
       "         ('or', 'the'): 70,\n",
       "         ('owners', 'or'): 1,\n",
       "         ('owners', 'of'): 2,\n",
       "         ('owners', 'managers'): 1,\n",
       "         ('owners', 'small'): 2,\n",
       "         ('of', 'owners'): 2,\n",
       "         ('of', 'small'): 12,\n",
       "         ('of', 'businesses'): 2,\n",
       "         ('small', 'of'): 12,\n",
       "         ('small', 'businesses'): 2,\n",
       "         ('small', 'owners'): 2,\n",
       "         ('small', ','): 12,\n",
       "         ('businesses', 'small'): 2,\n",
       "         ('businesses', ','): 2,\n",
       "         ('businesses', 'of'): 2,\n",
       "         ('businesses', 'indirectly'): 1,\n",
       "         (',', 'businesses'): 2,\n",
       "         (',', 'indirectly'): 2,\n",
       "         (',', 'small'): 12,\n",
       "         (',', 'aid'): 6,\n",
       "         ('indirectly', ','): 2,\n",
       "         ('indirectly', 'aid'): 1,\n",
       "         ('indirectly', 'businesses'): 1,\n",
       "         ('indirectly', 'in'): 1,\n",
       "         ('aid', 'indirectly'): 1,\n",
       "         ('aid', 'in'): 5,\n",
       "         ('aid', ','): 6,\n",
       "         ('aid', 'community'): 2,\n",
       "         ('in', 'aid'): 5,\n",
       "         ('in', 'community'): 3,\n",
       "         ('in', 'indirectly'): 1,\n",
       "         ('in', 'development'): 15,\n",
       "         ('community', 'in'): 3,\n",
       "         ('community', 'development'): 4,\n",
       "         ('community', 'aid'): 2,\n",
       "         ('community', 'programs'): 2,\n",
       "         ('development', 'community'): 4,\n",
       "         ('development', 'programs'): 7,\n",
       "         ('development', 'in'): 15,\n",
       "         ('development', '.'): 15,\n",
       "         ('programs', 'development'): 7,\n",
       "         ('programs', '.'): 8,\n",
       "         ('programs', 'community'): 2,\n",
       "         ('are', 'they'): 17,\n",
       "         ('are', 'written'): 1,\n",
       "         ('are', 'by'): 20,\n",
       "         ('written', 'are'): 1,\n",
       "         ('written', 'by'): 1,\n",
       "         ('written', 'they'): 1,\n",
       "         ('written', 'specialists'): 1,\n",
       "         ('by', 'written'): 1,\n",
       "         ('by', 'specialists'): 1,\n",
       "         ('by', 'are'): 20,\n",
       "         ('by', 'in'): 13,\n",
       "         ('specialists', 'by'): 1,\n",
       "         ('specialists', 'in'): 3,\n",
       "         ('specialists', 'written'): 1,\n",
       "         ('specialists', 'numerous'): 1,\n",
       "         ('in', 'specialists'): 3,\n",
       "         ('in', 'numerous'): 1,\n",
       "         ('in', 'by'): 13,\n",
       "         ('in', 'types'): 1,\n",
       "         ('numerous', 'in'): 1,\n",
       "         ('numerous', 'types'): 1,\n",
       "         ('numerous', 'specialists'): 1,\n",
       "         ('numerous', 'of'): 2,\n",
       "         ('types', 'numerous'): 1,\n",
       "         ('types', 'of'): 14,\n",
       "         ('types', 'in'): 1,\n",
       "         ('types', 'business'): 1,\n",
       "         ('of', 'types'): 16,\n",
       "         ('of', 'numerous'): 2,\n",
       "         ('of', 'enterprises'): 1,\n",
       "         ('business', 'enterprises'): 2,\n",
       "         ('business', 'types'): 1,\n",
       "         ('enterprises', 'business'): 2,\n",
       "         ('enterprises', ','): 1,\n",
       "         ('enterprises', 'of'): 1,\n",
       "         ('enterprises', 'cover'): 1,\n",
       "         (',', 'enterprises'): 1,\n",
       "         (',', 'cover'): 3,\n",
       "         (',', 'a'): 141,\n",
       "         ('cover', ','): 3,\n",
       "         ('cover', 'a'): 1,\n",
       "         ('cover', 'enterprises'): 1,\n",
       "         ('cover', 'wide'): 1,\n",
       "         ('a', 'cover'): 1,\n",
       "         ('a', 'wide'): 5,\n",
       "         ('a', ','): 140,\n",
       "         ('a', 'range'): 2,\n",
       "         ('wide', 'a'): 5,\n",
       "         ('wide', 'range'): 1,\n",
       "         ('wide', 'cover'): 1,\n",
       "         ('wide', 'of'): 5,\n",
       "         ('range', 'wide'): 1,\n",
       "         ('range', 'of'): 8,\n",
       "         ('range', 'a'): 2,\n",
       "         ('range', 'subjects'): 1,\n",
       "         ('of', 'range'): 8,\n",
       "         ('of', 'subjects'): 4,\n",
       "         ('of', 'wide'): 5,\n",
       "         ('subjects', 'of'): 4,\n",
       "         ('subjects', ','): 1,\n",
       "         ('subjects', 'range'): 1,\n",
       "         ('subjects', 'and'): 3,\n",
       "         (',', 'subjects'): 1,\n",
       "         (',', 'are'): 67,\n",
       "         ('and', 'are'): 33,\n",
       "         ('and', 'subjects'): 3,\n",
       "         ('and', 'directed'): 8,\n",
       "         ('are', 'and'): 34,\n",
       "         ('are', 'directed'): 2,\n",
       "         ('are', ','): 67,\n",
       "         ('directed', 'are'): 2,\n",
       "         ('directed', 'to'): 9,\n",
       "         ('directed', 'and'): 8,\n",
       "         ('directed', 'the'): 5,\n",
       "         ('to', 'directed'): 9,\n",
       "         ('to', 'needs'): 3,\n",
       "         ('the', 'needs'): 7,\n",
       "         ('the', 'directed'): 5,\n",
       "         ('needs', 'the'): 7,\n",
       "         ('needs', 'and'): 3,\n",
       "         ('needs', 'to'): 3,\n",
       "         ('needs', 'interests'): 1,\n",
       "         ('and', 'needs'): 3,\n",
       "         ('and', 'interests'): 3,\n",
       "         ('interests', 'and'): 3,\n",
       "         ('interests', 'of'): 8,\n",
       "         ('interests', 'needs'): 1,\n",
       "         ('interests', 'the'): 8,\n",
       "         ('of', 'interests'): 8,\n",
       "         ('the', 'small'): 12,\n",
       "         ('the', 'interests'): 8,\n",
       "         ('the', 'firm'): 4,\n",
       "         ('small', 'firm'): 1,\n",
       "         ('small', '.'): 5,\n",
       "         ('firm', 'small'): 1,\n",
       "         ('firm', '.'): 1,\n",
       "         ('firm', 'the'): 4,\n",
       "         ('offers', 'sba'): 1,\n",
       "         ('offers', 'administrative'): 1,\n",
       "         ('offers', 'management'): 1,\n",
       "         ('administrative', 'offers'): 1,\n",
       "         ('administrative', 'management'): 1,\n",
       "         ('administrative', 'sba'): 1,\n",
       "         ('administrative', 'courses'): 1,\n",
       "         ('management', 'administrative'): 1,\n",
       "         ('management', 'courses'): 1,\n",
       "         ('management', 'offers'): 1,\n",
       "         ('management', ','): 10,\n",
       "         ('courses', 'management'): 1,\n",
       "         ('courses', ','): 4,\n",
       "         ('courses', 'administrative'): 1,\n",
       "         ('courses', 'which'): 1,\n",
       "         (',', 'courses'): 4,\n",
       "         (',', 'which'): 54,\n",
       "         (',', 'management'): 10,\n",
       "         ('which', ','): 54,\n",
       "         ('which', 'are'): 23,\n",
       "         ('which', 'courses'): 1,\n",
       "         ('which', 'designed'): 2,\n",
       "         ('are', 'which'): 23,\n",
       "         ('are', 'designed'): 5,\n",
       "         ('designed', 'are'): 5,\n",
       "         ('designed', 'to'): 17,\n",
       "         ('designed', 'which'): 2,\n",
       "         ('designed', 'improve'): 1,\n",
       "         ('to', 'designed'): 17,\n",
       "         ('to', 'improve'): 2,\n",
       "         ('improve', 'to'): 2,\n",
       "         ('improve', 'the'): 2,\n",
       "         ('improve', 'designed'): 1,\n",
       "         ('improve', 'management'): 1,\n",
       "         ('the', 'improve'): 2,\n",
       "         ('the', 'management'): 8,\n",
       "         ('the', 'efficiency'): 1,\n",
       "         ('management', 'the'): 9,\n",
       "         ('management', 'efficiency'): 1,\n",
       "         ('management', 'improve'): 1,\n",
       "         ('efficiency', 'management'): 1,\n",
       "         ('efficiency', 'and'): 3,\n",
       "         ('efficiency', 'the'): 1,\n",
       "         ('efficiency', '``'): 1,\n",
       "         ('and', 'efficiency'): 3,\n",
       "         ('and', '``'): 17,\n",
       "         ('and', 'know-how'): 1,\n",
       "         ('``', 'and'): 17,\n",
       "         ('``', 'know-how'): 1,\n",
       "         ('``', 'efficiency'): 1,\n",
       "         ('``', \"''\"): 37,\n",
       "         ('know-how', '``'): 1,\n",
       "         ('know-how', \"''\"): 1,\n",
       "         ('know-how', 'and'): 1,\n",
       "         ('know-how', 'of'): 1,\n",
       "         (\"''\", 'know-how'): 1,\n",
       "         (\"''\", 'of'): 7,\n",
       "         (\"''\", '``'): 37,\n",
       "         (\"''\", 'small'): 1,\n",
       "         ('of', \"''\"): 7,\n",
       "         ('of', 'know-how'): 1,\n",
       "         ('small', \"''\"): 1,\n",
       "         ('small', 'concerns'): 13,\n",
       "         ('business', 'concerns'): 13,\n",
       "         ('business', 'within'): 1,\n",
       "         ('concerns', 'business'): 13,\n",
       "         ('concerns', 'within'): 1,\n",
       "         ('concerns', 'small'): 13,\n",
       "         ('concerns', 'a'): 1,\n",
       "         ('within', 'concerns'): 1,\n",
       "         ('within', 'a'): 6,\n",
       "         ('within', 'business'): 1,\n",
       "         ('within', 'community'): 1,\n",
       "         ('a', 'within'): 8,\n",
       "         ('a', 'community'): 2,\n",
       "         ('a', 'concerns'): 1,\n",
       "         ('a', '.'): 19,\n",
       "         ('community', 'a'): 2,\n",
       "         ('community', '.'): 6,\n",
       "         ('community', 'within'): 1,\n",
       "         ('cosponsors', 'sba'): 1,\n",
       "         ('cosponsors', 'these'): 1,\n",
       "         ('cosponsors', 'courses'): 1,\n",
       "         ('these', 'cosponsors'): 1,\n",
       "         ('these', 'courses'): 1,\n",
       "         ('these', 'sba'): 1,\n",
       "         ('these', 'with'): 5,\n",
       "         ('courses', 'these'): 1,\n",
       "         ('courses', 'with'): 1,\n",
       "         ('courses', 'cosponsors'): 1,\n",
       "         ('courses', 'educational'): 1,\n",
       "         ('with', 'courses'): 1,\n",
       "         ('with', 'educational'): 2,\n",
       "         ('with', 'these'): 4,\n",
       "         ('with', 'institutions'): 2,\n",
       "         ('educational', 'with'): 2,\n",
       "         ('educational', 'institutions'): 2,\n",
       "         ('educational', 'courses'): 1,\n",
       "         ('educational', 'and'): 6,\n",
       "         ('institutions', 'educational'): 2,\n",
       "         ('institutions', 'and'): 8,\n",
       "         ('institutions', 'with'): 2,\n",
       "         ('institutions', 'community'): 1,\n",
       "         ('and', 'institutions'): 8,\n",
       "         ('and', 'community'): 3,\n",
       "         ('and', 'educational'): 6,\n",
       "         ('and', 'groups'): 3,\n",
       "         ('community', 'and'): 3,\n",
       "         ('community', 'groups'): 1,\n",
       "         ('community', 'institutions'): 1,\n",
       "         ('groups', 'community'): 1,\n",
       "         ('groups', '.'): 3,\n",
       "         ('groups', 'and'): 3,\n",
       "         ('the', \"sba's\"): 1,\n",
       "         (\"sba's\", 'the'): 1,\n",
       "         (\"sba's\", 'management'): 1,\n",
       "         (\"sba's\", 'through'): 1,\n",
       "         (\"sba's\", 'counseling'): 1,\n",
       "         ('management', \"sba's\"): 1,\n",
       "         ('management', 'counseling'): 1,\n",
       "         ('management', 'program'): 1,\n",
       "         ('counseling', 'management'): 1,\n",
       "         ('counseling', 'program'): 1,\n",
       "         ('counseling', \"sba's\"): 1,\n",
       "         ('counseling', ','): 3,\n",
       "         ('program', 'counseling'): 1,\n",
       "         ('program', ','): 20,\n",
       "         ('program', 'management'): 1,\n",
       "         ('program', 'practical'): 1,\n",
       "         (',', 'program'): 20,\n",
       "         (',', 'practical'): 2,\n",
       "         (',', 'counseling'): 3,\n",
       "         (',', ','): 840,\n",
       "         ('practical', ','): 2,\n",
       "         ('practical', 'program'): 1,\n",
       "         ('practical', 'personalized'): 1,\n",
       "         (',', 'personalized'): 1,\n",
       "         (',', 'advice'): 3,\n",
       "         ('personalized', ','): 1,\n",
       "         ('personalized', 'advice'): 1,\n",
       "         ('personalized', 'practical'): 1,\n",
       "         ('personalized', 'on'): 1,\n",
       "         ('advice', 'personalized'): 1,\n",
       "         ('advice', ','): 3,\n",
       "         ('advice', 'sound'): 1,\n",
       "         ('on', 'sound'): 3,\n",
       "         ('on', 'personalized'): 1,\n",
       "         ('on', 'management'): 1,\n",
       "         ('sound', 'on'): 3,\n",
       "         ('sound', 'management'): 1,\n",
       "         ('sound', 'advice'): 1,\n",
       "         ('sound', 'principles'): 1,\n",
       "         ('management', 'sound'): 1,\n",
       "         ('management', 'principles'): 1,\n",
       "         ('management', 'on'): 1,\n",
       "         ('management', 'is'): 3,\n",
       "         ('principles', 'management'): 1,\n",
       "         ('principles', 'is'): 1,\n",
       "         ('principles', 'sound'): 1,\n",
       "         ('principles', 'available'): 1,\n",
       "         ('is', 'principles'): 1,\n",
       "         ('is', 'management'): 3,\n",
       "         ('is', 'upon'): 1,\n",
       "         ('available', 'upon'): 1,\n",
       "         ('available', 'principles'): 1,\n",
       "         ('available', 'request'): 1,\n",
       "         ('upon', 'available'): 1,\n",
       "         ('upon', 'request'): 4,\n",
       "         ('upon', 'is'): 1,\n",
       "         ('upon', 'to'): 4,\n",
       "         ('request', 'upon'): 4,\n",
       "         ('request', 'to'): 2,\n",
       "         ('request', 'available'): 1,\n",
       "         ('request', 'both'): 1,\n",
       "         ('to', 'request'): 2,\n",
       "         ('to', 'both'): 3,\n",
       "         ('to', 'upon'): 4,\n",
       "         ('to', 'prospective'): 2,\n",
       "         ('both', 'to'): 3,\n",
       "         ('both', 'prospective'): 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik_skipgram = Counter(skip_grams_generated(window_size=2))\n",
    "\n",
    "X_ik_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i, w_j, X_ik):\n",
    "        \n",
    "    #check whether the co-occurrences exist between these two words\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #if does not exist, set it to 1, basically smoothing technique\n",
    "                \n",
    "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
    "    alpha = 0.75 \n",
    "    \n",
    "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha  #scale it\n",
    "    else:\n",
    "        result = 1  #if is greater than max, set it to 1 maximum\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27103203it [01:08, 396371.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_ik = {}  #for keeping the co-occurences\n",
    "weighting_dic = {} #scaling the percentage of sampling\n",
    "# Use tqdm as amanda recommend!\n",
    "for bigram in tqdm(combinations_with_replacement(vocab, 2)):\n",
    "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
    "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
    "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
    "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
    "\n",
    "# Do not print if you have large data, otherwise your pc will froze.\n",
    "#print(f\"{X_ik=}\")\n",
    "#print(f\"{weighting_dic=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'office',\n",
       "  'of',\n",
       "  'business',\n",
       "  'economics',\n",
       "  '(',\n",
       "  'obe',\n",
       "  ')',\n",
       "  'of',\n",
       "  'the',\n",
       "  'u.s.',\n",
       "  'department',\n",
       "  'of',\n",
       "  'commerce',\n",
       "  'provides',\n",
       "  'basic',\n",
       "  'measures',\n",
       "  'of',\n",
       "  'the',\n",
       "  'national',\n",
       "  'economy',\n",
       "  'and',\n",
       "  'current',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'short-run',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'the',\n",
       "  'economic',\n",
       "  'situation',\n",
       "  'and',\n",
       "  'business',\n",
       "  'outlook',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'develops',\n",
       "  'and',\n",
       "  'analyzes',\n",
       "  'the',\n",
       "  'national',\n",
       "  'income',\n",
       "  ',',\n",
       "  'balance',\n",
       "  'of',\n",
       "  'international',\n",
       "  'payments',\n",
       "  ',',\n",
       "  'and',\n",
       "  'many',\n",
       "  'other',\n",
       "  'business',\n",
       "  'indicators',\n",
       "  '.'],\n",
       " ['such',\n",
       "  'measures',\n",
       "  'are',\n",
       "  'essential',\n",
       "  'to',\n",
       "  'its',\n",
       "  'job',\n",
       "  'of',\n",
       "  'presenting',\n",
       "  'business',\n",
       "  'and',\n",
       "  'government',\n",
       "  'with',\n",
       "  'the',\n",
       "  'facts',\n",
       "  'required',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'the',\n",
       "  'objective',\n",
       "  'of',\n",
       "  'expanding',\n",
       "  'business',\n",
       "  'and',\n",
       "  'improving',\n",
       "  'the',\n",
       "  'operation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'economy',\n",
       "  '.'],\n",
       " ['contact'],\n",
       " ['for',\n",
       "  'further',\n",
       "  'information',\n",
       "  'contact',\n",
       "  'director',\n",
       "  ',',\n",
       "  'office',\n",
       "  'of',\n",
       "  'business',\n",
       "  'economics',\n",
       "  ',',\n",
       "  'u.s.',\n",
       "  'department',\n",
       "  'of',\n",
       "  'commerce',\n",
       "  ',',\n",
       "  'washington',\n",
       "  '25',\n",
       "  ',',\n",
       "  'd.c.',\n",
       "  '.']]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:5] #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "    \n",
    "    #convert to id since our skip_grams is word, not yet id\n",
    "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_coocs  = []\n",
    "    random_weightings = []\n",
    "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
    "        \n",
    "        #get cooc\n",
    "        pair = skip_grams[i]\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1\n",
    "        random_coocs.append([math.log(cooc)])\n",
    "        \n",
    "        #get weighting\n",
    "        weighting = weighting_dic[pair]\n",
    "        random_weightings.append([weighting])\n",
    "                    \n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[7146]\n",
      " [4946]]\n",
      "Target:  [[ 343]\n",
      " [6757]]\n",
      "Cooc:  [[0.69314718]\n",
      " [0.69314718]]\n",
      "Weighting:  [[0.05318296]\n",
      " [0.05318296]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "skip_grams = skip_grams_generated(window_size=2)\n",
    "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "print(\"Cooc: \", cooc_batch)\n",
    "print(\"Weighting: \", weighting_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare parameters\n",
    "voc_size = len(vocab)\n",
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 100 #so we can later plot\n",
    "model          = GloVe(voc_size, embedding_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | cost: 93.132736 | time: 0m 0s\n",
      "Epoch: 200 | cost: 121.045647 | time: 0m 0s\n",
      "Epoch: 300 | cost: 77.716263 | time: 0m 0s\n",
      "Epoch: 400 | cost: 197.487549 | time: 0m 0s\n",
      "Epoch: 500 | cost: 465.276184 | time: 0m 0s\n",
      "Total time: 0m 42s\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_training = time.time()\n",
    "# Training\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
    "    input_batch  = torch.LongTensor(input_batch).to(device)         #[batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch).to(device)        #[batch_size, 1]\n",
    "    cooc_batch   = torch.FloatTensor(cooc_batch).to(device)         #[batch_size, 1]\n",
    "    weighting_batch = torch.FloatTensor(weighting_batch).to(device) #[batch_size, 1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "end_training = time.time()\n",
    "start_min, end_min = epoch_time(start_training, end_training)\n",
    "print(f'Total time: {start_min}m {end_min}s\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/GloVe.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory /Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe\n",
      "/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    " \n",
    "# # get current directory\n",
    "# path = os.getcwd()\n",
    "# print(\"Current Directory\", path)\n",
    "\n",
    "# print(os.path.abspath(os.path.join(path, os.pardir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skipgram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, word_sequence, window_size=1):\n",
    "\n",
    "# I fix a little from Chaky so we can modify the window_size\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
    "            target = word2index[sent[i]]\n",
    "            \n",
    "            context = list()\n",
    "            # ['a', 'b', 'c', 'd', 'e'] if window size = 2 and target is c\n",
    "            # this is basically append 'b', 'd', 'a', 'e' into context\n",
    "            \n",
    "            for j in range(window_size):\n",
    "                \n",
    "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
    "                    context.append(word2index[sent[i - (j + 1)]])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
    "                    context.append(word2index[sent[i + (j + 1)]])\n",
    "            \n",
    "            #context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[ 885]\n",
      " [1090]]\n",
      "Target:  [[6630]\n",
      " [1090]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch = random_batch(batch_size, corpus, 2)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_words, target_words, all_vocabs):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        all_embeds    = self.embedding_u(all_vocabs) #   [batch_size, voc_size, emb_size]\n",
    "        \n",
    "        scores      = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "\n",
    "        norm_scores = all_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, voc_size, emb_size] @ [batch_size, emb_size, 1] = [batch_size, voc_size, 1] = [batch_size, voc_size]\n",
    "\n",
    "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
    "        # scalar (loss must be scalar)    \n",
    "            \n",
    "        return nll # negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 100 #so we can later plot\n",
    "model          = Skipgram(voc_size, embedding_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 7362])\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "#use for the normalized term in the probability calculation\n",
    "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, len(vocab))  # [batch_size, voc_size]\n",
    "print(all_vocabs.shape)\n",
    "all_vocabs = all_vocabs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | cost: 36.343662 | time: 0m 27s\n",
      "Epoch: 200 | cost: 33.256165 | time: 0m 26s\n",
      "Epoch: 300 | cost: 23.621540 | time: 0m 27s\n",
      "Epoch: 400 | cost: 35.052223 | time: 0m 27s\n",
      "Epoch: 500 | cost: 39.768555 | time: 0m 28s\n",
      "Total time use in skipgram with window size of 2 2 miniute(s) 17 second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training\n",
    "start_train_time = time.time()\n",
    "num_epochs = 500 # At first I intend to use 5,000 but it's too much for my PC\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    input_batch, target_batch = random_batch(batch_size, corpus, window_size=2)\n",
    "    input_batch  = torch.LongTensor(input_batch).to(device)  #[batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch).to(device) #[batch_size, 1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(input_batch, target_batch, all_vocabs)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        end = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "        start = time.time()\n",
    "end_train_time = time.time()\n",
    "train_time_mins, train_time_secs = epoch_time(start_train_time, end_train_time)\n",
    "print(f'Total time use in skipgram with window size of 2 {train_time_mins} miniute(s) {train_time_secs} second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/Skipgram.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random batch for cbow\n",
    "\n",
    "def random_batch_cbow(batch_size, word_sequence, window_size=1):\n",
    "\n",
    "    cbow = []\n",
    "\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
    "            target = word2index[sent[i]]\n",
    "            context = list()\n",
    "            \n",
    "            for j in range(window_size):\n",
    "                \n",
    "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
    "                    context.append(word2index[sent[i - (j + 1)]])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
    "                    context.append(word2index[sent[i + (j + 1)]])\n",
    "            \n",
    "            # This part is different from skipgram\n",
    "            # Now we use all context as input and target as label\n",
    "            for w in context:\n",
    "                cbow.append([context, target])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(cbow)), batch_size, replace=False) #randomly pick without replacement\n",
    "    \n",
    "    for i in random_index:\n",
    "        random_inputs.append(cbow[i][0])  # Context word that we want as input\n",
    "        random_labels.append([cbow[i][1]])  # Target word that we want as label\n",
    "    \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[1090 2300 4845 5052]\n",
      " [5341 5530 6484 3484]]\n",
      "Target:  [[518]\n",
      " [732]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch = random_batch_cbow(batch_size, corpus, 2)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cbow(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(Cbow,self).__init__() # Not sure why we super(Cbow) or super(Skipgram)?\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_words, target_words, all_vocabs):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        all_embeds    = self.embedding_u(all_vocabs) #   [batch_size, voc_size, emb_size]\n",
    "        \n",
    "        scores      = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "\n",
    "        norm_scores = all_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, voc_size, emb_size] @ [batch_size, emb_size, 1] = [batch_size, voc_size, 1] = [batch_size, voc_size]\n",
    "\n",
    "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
    "        # scalar (loss must be scalar)    \n",
    "            \n",
    "        return nll # negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 100 #so we can later plot\n",
    "model          = Cbow(voc_size, embedding_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | cost: 34.118095 | time: 0m 20s\n",
      "Epoch: 200 | cost: 38.658112 | time: 0m 19s\n",
      "Epoch: 300 | cost: 29.663013 | time: 0m 19s\n",
      "Epoch: 400 | cost: 32.212715 | time: 0m 20s\n",
      "Epoch: 500 | cost: 29.172155 | time: 0m 19s\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import time\n",
    "num_epochs = 500\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    input_batch, target_batch = random_batch_cbow(batch_size, corpus, 1)\n",
    "    input_batch  = torch.LongTensor(input_batch).to(device)  #[batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch).to(device) #[batch_size, 1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(input_batch, target_batch, all_vocabs)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        end = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/CBOW.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skipgram with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 70117)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus))\n",
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "\n",
    "# Check if the counting work\n",
    "word_count['car'], num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigram table\n",
    "Z = 0.001\n",
    "unigram_table = []\n",
    "\n",
    "for vo in vocab:\n",
    "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'appeal': 1,\n",
       "         'required': 3,\n",
       "         'agreed': 1,\n",
       "         'includes': 1,\n",
       "         'rates': 1,\n",
       "         'international': 2,\n",
       "         'city': 1,\n",
       "         'sources': 1,\n",
       "         'did': 2,\n",
       "         'few': 2,\n",
       "         'place': 2,\n",
       "         'trails': 1,\n",
       "         'first': 5,\n",
       "         '1': 7,\n",
       "         'nighttime': 1,\n",
       "         'corporation': 1,\n",
       "         'described': 1,\n",
       "         'detail': 1,\n",
       "         '8': 1,\n",
       "         'christiana': 1,\n",
       "         'continue': 1,\n",
       "         'pool': 2,\n",
       "         'day': 4,\n",
       "         'planned': 1,\n",
       "         'week': 2,\n",
       "         'payments': 2,\n",
       "         'period': 4,\n",
       "         'private': 1,\n",
       "         'supply': 1,\n",
       "         'outstanding': 1,\n",
       "         'question': 1,\n",
       "         'current': 2,\n",
       "         '1960': 5,\n",
       "         'who': 6,\n",
       "         'available': 4,\n",
       "         'products': 2,\n",
       "         'aid': 3,\n",
       "         'manager': 1,\n",
       "         'run': 1,\n",
       "         'working': 1,\n",
       "         'secretary': 4,\n",
       "         'home': 2,\n",
       "         'either': 1,\n",
       "         'allocation': 1,\n",
       "         'cooperation': 1,\n",
       "         'established': 2,\n",
       "         'limited': 1,\n",
       "         'result': 2,\n",
       "         'lord': 1,\n",
       "         'grant': 1,\n",
       "         'army': 1,\n",
       "         '``': 8,\n",
       "         'though': 1,\n",
       "         'excluding': 1,\n",
       "         'rather': 1,\n",
       "         'technical': 2,\n",
       "         'industry': 2,\n",
       "         'companies': 1,\n",
       "         'over': 4,\n",
       "         'article': 2,\n",
       "         'title': 2,\n",
       "         'if': 8,\n",
       "         'within': 4,\n",
       "         '6': 2,\n",
       "         'little': 1,\n",
       "         'speaker': 2,\n",
       "         'strategic': 1,\n",
       "         'automatic': 1,\n",
       "         'persons': 1,\n",
       "         'arts': 1,\n",
       "         'communities': 1,\n",
       "         'program': 6,\n",
       "         'records': 1,\n",
       "         'electronic': 2,\n",
       "         '11': 1,\n",
       "         'reserve': 1,\n",
       "         'machinery': 1,\n",
       "         'military': 4,\n",
       "         'reports': 1,\n",
       "         'habitat': 1,\n",
       "         'minimum': 1,\n",
       "         'campus': 1,\n",
       "         'political': 1,\n",
       "         'itself': 1,\n",
       "         'term': 1,\n",
       "         'close': 2,\n",
       "         'largest': 1,\n",
       "         'firms': 1,\n",
       "         'awards': 1,\n",
       "         'mind': 1,\n",
       "         'contract': 1,\n",
       "         'so': 6,\n",
       "         'into': 5,\n",
       "         'sunset': 1,\n",
       "         'additional': 2,\n",
       "         'above': 3,\n",
       "         'factors': 1,\n",
       "         'upon': 4,\n",
       "         'understanding': 1,\n",
       "         'currently': 1,\n",
       "         'defense': 3,\n",
       "         'complex': 1,\n",
       "         'cases': 1,\n",
       "         '1961': 4,\n",
       "         'potential': 1,\n",
       "         'when': 5,\n",
       "         'data': 2,\n",
       "         'paragraphs': 1,\n",
       "         'broad': 1,\n",
       "         'placed': 1,\n",
       "         'assessors': 2,\n",
       "         'range': 1,\n",
       "         'investigation': 1,\n",
       "         'returns': 1,\n",
       "         'more': 8,\n",
       "         'payment': 3,\n",
       "         '1958': 1,\n",
       "         'performance': 1,\n",
       "         'forests': 1,\n",
       "         'tool': 1,\n",
       "         'nor': 1,\n",
       "         'came': 1,\n",
       "         'position': 2,\n",
       "         'committee': 1,\n",
       "         'costs': 2,\n",
       "         'helium': 1,\n",
       "         'until': 2,\n",
       "         'change': 1,\n",
       "         'light': 1,\n",
       "         'found': 2,\n",
       "         'such': 12,\n",
       "         'practices': 1,\n",
       "         'pathology': 3,\n",
       "         'parts': 1,\n",
       "         'providing': 1,\n",
       "         'progress': 2,\n",
       "         'exceed': 1,\n",
       "         'cranston': 1,\n",
       "         'york': 3,\n",
       "         'representatives': 2,\n",
       "         'relationship': 1,\n",
       "         'rules': 1,\n",
       "         'skywave': 3,\n",
       "         'unless': 1,\n",
       "         'long-term': 1,\n",
       "         'far': 1,\n",
       "         'areas': 2,\n",
       "         'washington': 2,\n",
       "         'personnel': 2,\n",
       "         'believe': 1,\n",
       "         'manufacture': 1,\n",
       "         'never': 1,\n",
       "         'sum': 1,\n",
       "         'recommendation': 1,\n",
       "         '15': 2,\n",
       "         'self-help': 1,\n",
       "         'he': 10,\n",
       "         'contributed': 1,\n",
       "         'investment': 1,\n",
       "         'adjustment': 1,\n",
       "         'free': 1,\n",
       "         'legal': 1,\n",
       "         'without': 2,\n",
       "         'state-owned': 1,\n",
       "         'congress': 3,\n",
       "         'methods': 1,\n",
       "         'give': 2,\n",
       "         'sales': 3,\n",
       "         'experience': 1,\n",
       "         'through': 5,\n",
       "         '20': 1,\n",
       "         'use': 6,\n",
       "         'particular': 2,\n",
       "         'textile': 1,\n",
       "         'mr.': 5,\n",
       "         'answer': 1,\n",
       "         'air': 2,\n",
       "         'greatest': 1,\n",
       "         'during': 6,\n",
       "         'institute': 2,\n",
       "         'include': 2,\n",
       "         'full': 2,\n",
       "         'basis': 3,\n",
       "         'responsible': 1,\n",
       "         'offices': 1,\n",
       "         'basement': 1,\n",
       "         'rupees': 1,\n",
       "         ',': 103,\n",
       "         'principal': 2,\n",
       "         'cause': 1,\n",
       "         'field': 2,\n",
       "         'work': 4,\n",
       "         'tax': 6,\n",
       "         'responsibility': 2,\n",
       "         'efforts': 1,\n",
       "         'expenditures': 2,\n",
       "         'probably': 1,\n",
       "         'community': 2,\n",
       "         'staff': 2,\n",
       "         'management': 3,\n",
       "         'retired': 1,\n",
       "         'might': 1,\n",
       "         'group': 1,\n",
       "         'think': 1,\n",
       "         'sharpe': 2,\n",
       "         'producing': 1,\n",
       "         'goals': 1,\n",
       "         'already': 1,\n",
       "         'bureau': 1,\n",
       "         'approval': 1,\n",
       "         'proclamation': 1,\n",
       "         'united': 10,\n",
       "         'banks': 1,\n",
       "         'whose': 1,\n",
       "         'entitled': 2,\n",
       "         'due': 2,\n",
       "         'true': 1,\n",
       "         'request': 1,\n",
       "         'adjustments': 1,\n",
       "         'lack': 1,\n",
       "         'last': 2,\n",
       "         'since': 3,\n",
       "         'permanent': 1,\n",
       "         'out': 4,\n",
       "         'therefore': 2,\n",
       "         'serious': 1,\n",
       "         'estimated': 2,\n",
       "         'being': 3,\n",
       "         'ago': 1,\n",
       "         'components': 1,\n",
       "         'caused': 1,\n",
       "         'modern': 1,\n",
       "         'deduct': 1,\n",
       "         'miles': 2,\n",
       "         'july': 2,\n",
       "         'rhode': 5,\n",
       "         'family': 1,\n",
       "         'initial': 1,\n",
       "         'history': 1,\n",
       "         'pursuant': 2,\n",
       "         'world': 4,\n",
       "         'market': 3,\n",
       "         'location': 1,\n",
       "         'boats': 2,\n",
       "         'purposes': 3,\n",
       "         'tangible': 1,\n",
       "         'can': 8,\n",
       "         'publications': 1,\n",
       "         'example': 1,\n",
       "         'freedom': 2,\n",
       "         'v.': 1,\n",
       "         'conditions': 2,\n",
       "         'item': 2,\n",
       "         'too': 1,\n",
       "         'calendars': 1,\n",
       "         'those': 5,\n",
       "         '-': 1,\n",
       "         'surface': 1,\n",
       "         'including': 2,\n",
       "         'opportunity': 2,\n",
       "         'office': 2,\n",
       "         ';': 22,\n",
       "         'maintain': 1,\n",
       "         'techniques': 1,\n",
       "         'said': 2,\n",
       "         'after': 3,\n",
       "         'trial': 1,\n",
       "         'advantages': 1,\n",
       "         'advisory': 1,\n",
       "         'federal': 4,\n",
       "         'institutions': 1,\n",
       "         'thousand': 1,\n",
       "         'under': 7,\n",
       "         '50%': 1,\n",
       "         'from': 14,\n",
       "         'thereof': 1,\n",
       "         'authority': 1,\n",
       "         'cooperative': 1,\n",
       "         'to': 65,\n",
       "         'reflected': 1,\n",
       "         'agreement': 3,\n",
       "         'relating': 1,\n",
       "         'pay': 3,\n",
       "         'reason': 1,\n",
       "         'special': 2,\n",
       "         'hearing': 2,\n",
       "         'measured': 1,\n",
       "         'affairs': 1,\n",
       "         'equipment': 3,\n",
       "         'before': 3,\n",
       "         'u.': 2,\n",
       "         'you': 6,\n",
       "         'assignment': 1,\n",
       "         'kind': 1,\n",
       "         'problems': 3,\n",
       "         'power': 1,\n",
       "         'months': 1,\n",
       "         'where': 4,\n",
       "         'trustees': 1,\n",
       "         'gear': 1,\n",
       "         'issues': 1,\n",
       "         'decisions': 1,\n",
       "         'carry': 1,\n",
       "         'existing': 1,\n",
       "         'distributed': 1,\n",
       "         'find': 1,\n",
       "         'wages': 1,\n",
       "         'officers': 1,\n",
       "         'executive': 1,\n",
       "         'contribute': 1,\n",
       "         'concrete': 1,\n",
       "         'ownership': 1,\n",
       "         'animals': 1,\n",
       "         'times': 2,\n",
       "         'their': 11,\n",
       "         'u.s.': 2,\n",
       "         'quality': 1,\n",
       "         'determined': 2,\n",
       "         'claim': 3,\n",
       "         'systems': 2,\n",
       "         'ground': 1,\n",
       "         '.': 81,\n",
       "         'your': 4,\n",
       "         'reasonable': 1,\n",
       "         'administration': 3,\n",
       "         'vocational': 1,\n",
       "         'civil': 1,\n",
       "         'financial': 2,\n",
       "         'all': 10,\n",
       "         'notte': 1,\n",
       "         'hope': 1,\n",
       "         'commission': 3,\n",
       "         'd.c.': 1,\n",
       "         'november': 1,\n",
       "         'particularly': 1,\n",
       "         'right': 1,\n",
       "         'exhibits': 1,\n",
       "         'one': 8,\n",
       "         'significance': 1,\n",
       "         'sec.': 1,\n",
       "         'view': 1,\n",
       "         'increasing': 1,\n",
       "         'information': 3,\n",
       "         'amount': 3,\n",
       "         'operations': 2,\n",
       "         'concerns': 2,\n",
       "         'appropriate': 1,\n",
       "         'capacity': 1,\n",
       "         'roads': 2,\n",
       "         'line': 2,\n",
       "         'entered': 1,\n",
       "         'pressure': 1,\n",
       "         'jr.': 2,\n",
       "         'phase': 1,\n",
       "         'account': 1,\n",
       "         'volunteers': 1,\n",
       "         'publication': 1,\n",
       "         'lower': 1,\n",
       "         'alaska': 1,\n",
       "         'promotion': 1,\n",
       "         'very': 2,\n",
       "         'take': 3,\n",
       "         'skilled': 1,\n",
       "         'naval': 1,\n",
       "         'followed': 1,\n",
       "         'export-import': 1,\n",
       "         \"brown's\": 1,\n",
       "         'student': 3,\n",
       "         'normal': 1,\n",
       "         'construction': 2,\n",
       "         'aircraft': 1,\n",
       "         'food': 1,\n",
       "         'employees': 2,\n",
       "         'athletic': 1,\n",
       "         'become': 1,\n",
       "         'still': 2,\n",
       "         'entire': 1,\n",
       "         'national': 5,\n",
       "         'john': 2,\n",
       "         'once': 1,\n",
       "         'strong': 1,\n",
       "         'business': 8,\n",
       "         'success': 1,\n",
       "         'others': 2,\n",
       "         'plant': 3,\n",
       "         'resulting': 1,\n",
       "         'should': 8,\n",
       "         'an': 13,\n",
       "         'hand': 1,\n",
       "         'country': 3,\n",
       "         'advice': 1,\n",
       "         'about': 6,\n",
       "         'now': 4,\n",
       "         'although': 1,\n",
       "         'long': 2,\n",
       "         'adjusted': 1,\n",
       "         'any': 9,\n",
       "         'outside': 1,\n",
       "         'shipments': 1,\n",
       "         \"officer's\": 1,\n",
       "         'e': 1,\n",
       "         'in': 55,\n",
       "         'allowances': 2,\n",
       "         'our': 10,\n",
       "         'universal': 1,\n",
       "         'frequencies': 1,\n",
       "         'must': 7,\n",
       "         'determine': 2,\n",
       "         'approach': 1,\n",
       "         'maximum': 1,\n",
       "         'has': 10,\n",
       "         'produced': 1,\n",
       "         'milling': 1,\n",
       "         'spectra': 1,\n",
       "         'project': 1,\n",
       "         'sets': 2,\n",
       "         'commodities': 1,\n",
       "         'peace': 4,\n",
       "         '2': 6,\n",
       "         'night': 1,\n",
       "         'regulations': 1,\n",
       "         'decision': 1,\n",
       "         'loans': 2,\n",
       "         'establish': 1,\n",
       "         'almost': 1,\n",
       "         'plans': 2,\n",
       "         'conference': 1,\n",
       "         'land': 2,\n",
       "         'type': 1,\n",
       "         'help': 2,\n",
       "         'time': 7,\n",
       "         'rate': 2,\n",
       "         'means': 2,\n",
       "         'uses': 1,\n",
       "         'primary': 1,\n",
       "         'extension': 1,\n",
       "         'timber': 1,\n",
       "         'system': 3,\n",
       "         'end': 2,\n",
       "         'difficult': 1,\n",
       "         'october': 1,\n",
       "         'vapor': 1,\n",
       "         'by': 22,\n",
       "         'interior': 1,\n",
       "         'vehicles': 3,\n",
       "         'recreation': 1,\n",
       "         'security': 2,\n",
       "         'governor': 2,\n",
       "         'af': 2,\n",
       "         'overseas': 1,\n",
       "         'wrong': 1,\n",
       "         'know': 1,\n",
       "         'forces': 3,\n",
       "         'six': 1,\n",
       "         'population': 1,\n",
       "         'meet': 1,\n",
       "         'were': 8,\n",
       "         'could': 3,\n",
       "         'along': 1,\n",
       "         'formed': 1,\n",
       "         'highway': 1,\n",
       "         'then': 1,\n",
       "         'at': 14,\n",
       "         'measures': 1,\n",
       "         'social': 1,\n",
       "         'between': 4,\n",
       "         'requirements': 2,\n",
       "         'is': 30,\n",
       "         'these': 10,\n",
       "         'rendered': 1,\n",
       "         'its': 9,\n",
       "         'december': 1,\n",
       "         'guam': 1,\n",
       "         'average': 2,\n",
       "         'public': 4,\n",
       "         'put': 1,\n",
       "         'filing': 1,\n",
       "         'students': 2,\n",
       "         'government': 8,\n",
       "         'constructed': 1,\n",
       "         '?': 5,\n",
       "         'actual': 1,\n",
       "         'maintenance': 2,\n",
       "         'building': 1,\n",
       "         'structure': 1,\n",
       "         'make': 4,\n",
       "         'professional': 1,\n",
       "         'town': 1,\n",
       "         'acres': 2,\n",
       "         'atomic': 1,\n",
       "         'programing': 1,\n",
       "         'values': 1,\n",
       "         'suitable': 1,\n",
       "         'matching': 1,\n",
       "         '104': 1,\n",
       "         'sound': 1,\n",
       "         'me': 1,\n",
       "         'cities': 2,\n",
       "         'original': 1,\n",
       "         'news': 1,\n",
       "         'demand': 1,\n",
       "         'several': 3,\n",
       "         'sam': 2,\n",
       "         'better': 2,\n",
       "         'money': 1,\n",
       "         'regular': 1,\n",
       "         'cannot': 1,\n",
       "         'health': 1,\n",
       "         'reduced': 1,\n",
       "         'markets': 1,\n",
       "         'share': 2,\n",
       "         'taking': 1,\n",
       "         'contact': 1,\n",
       "         'establishment': 1,\n",
       "         'much': 2,\n",
       "         'say': 1,\n",
       "         'chapter': 1,\n",
       "         'automobiles': 1,\n",
       "         'soon': 1,\n",
       "         'temperature': 1,\n",
       "         'rehabilitation': 1,\n",
       "         'each': 6,\n",
       "         'compared': 1,\n",
       "         'making': 2,\n",
       "         'days': 1,\n",
       "         ':': 7,\n",
       "         'law': 2,\n",
       "         'stations': 4,\n",
       "         '100': 1,\n",
       "         'year': 11,\n",
       "         'director': 2,\n",
       "         'matters': 1,\n",
       "         'groups': 1,\n",
       "         'motor': 1,\n",
       "         'department': 6,\n",
       "         'whether': 2,\n",
       "         'journal': 1,\n",
       "         'needs': 1,\n",
       "         'provision': 1,\n",
       "         'matter': 2,\n",
       "         'cuba': 1,\n",
       "         'file': 3,\n",
       "         'editor': 1,\n",
       "         'on': 21,\n",
       "         'promote': 1,\n",
       "         'effort': 2,\n",
       "         'provided': 3,\n",
       "         'd': 1,\n",
       "         'various': 2,\n",
       "         'sunday': 1,\n",
       "         'machine': 3,\n",
       "         'gross': 1,\n",
       "         'metal': 1,\n",
       "         'built': 1,\n",
       "         '&': 4,\n",
       "         'table': 1,\n",
       "         'early': 2,\n",
       "         'copies': 1,\n",
       "         '--': 9,\n",
       "         'yet': 1,\n",
       "         'credit': 2,\n",
       "         'losses': 1,\n",
       "         'growing': 1,\n",
       "         'support': 3,\n",
       "         'purchasing': 1,\n",
       "         'product': 1,\n",
       "         'facilities': 3,\n",
       "         'c': 2,\n",
       "         'association': 2,\n",
       "         'procurement': 1,\n",
       "         'mileage': 1,\n",
       "         'surplus': 1,\n",
       "         'interested': 2,\n",
       "         'process': 2,\n",
       "         'leadership': 1,\n",
       "         'stated': 1,\n",
       "         '30': 2,\n",
       "         'different': 1,\n",
       "         'space': 1,\n",
       "         'competition': 1,\n",
       "         'officials': 1,\n",
       "         'related': 1,\n",
       "         'consideration': 1,\n",
       "         'because': 3,\n",
       "         'called': 1,\n",
       "         'museum': 1,\n",
       "         'proposed': 2,\n",
       "         'finance': 1,\n",
       "         'least': 2,\n",
       "         'recent': 2,\n",
       "         'another': 2,\n",
       "         'fire': 1,\n",
       "         'island': 5,\n",
       "         'puerto': 2,\n",
       "         '12': 1,\n",
       "         'active': 1,\n",
       "         'owner': 1,\n",
       "         'acquisition': 1,\n",
       "         'denied': 1,\n",
       "         'source': 1,\n",
       "         'look': 1,\n",
       "         'foreign': 3,\n",
       "         'launched': 1,\n",
       "         'revenues': 1,\n",
       "         'application': 2,\n",
       "         'sponsored': 1,\n",
       "         '1959': 3,\n",
       "         'partnership': 1,\n",
       "         'justice': 1,\n",
       "         'show': 1,\n",
       "         'yarn': 1,\n",
       "         'allotments': 1,\n",
       "         'honor': 1,\n",
       "         'blockade': 1,\n",
       "         'have': 13,\n",
       "         'interest': 4,\n",
       "         'competitive': 1,\n",
       "         'selected': 1,\n",
       "         'assessment': 1,\n",
       "         'b.': 1,\n",
       "         'man': 1,\n",
       "         'further': 2,\n",
       "         'budget': 2,\n",
       "         'participate': 1,\n",
       "         'closely': 1,\n",
       "         'advanced': 1,\n",
       "         'force': 2,\n",
       "         'direct': 1,\n",
       "         'given': 2,\n",
       "         'both': 5,\n",
       "         'present': 3,\n",
       "         'significant': 1,\n",
       "         'serve': 2,\n",
       "         'forward': 1,\n",
       "         'order': 2,\n",
       "         'review': 1,\n",
       "         'single': 1,\n",
       "         'receive': 1,\n",
       "         'common': 1,\n",
       "         'electrical': 1,\n",
       "         'form': 3,\n",
       "         'develop': 1,\n",
       "         'the': 130,\n",
       "         'material': 1,\n",
       "         'developing': 1,\n",
       "         'reduction': 1,\n",
       "         'protection': 3,\n",
       "         'relatively': 1,\n",
       "         'half': 1,\n",
       "         'armed': 2,\n",
       "         'sba': 2,\n",
       "         'while': 2,\n",
       "         'educational': 1,\n",
       "         'percent': 2,\n",
       "         'person': 1,\n",
       "         'require': 1,\n",
       "         'cooperatives': 1,\n",
       "         'levels': 1,\n",
       "         'other': 12,\n",
       "         'method': 2,\n",
       "         'every': 2,\n",
       "         'received': 2,\n",
       "         'again': 1,\n",
       "         'governments': 2,\n",
       "         '9': 1,\n",
       "         'june': 3,\n",
       "         'what': 4,\n",
       "         'greater': 2,\n",
       "         'departments': 1,\n",
       "         'travel': 1,\n",
       "         'permitted': 1,\n",
       "         'made': 8,\n",
       "         'how': 2,\n",
       "         'agricultural': 1,\n",
       "         'fact': 1,\n",
       "         'subsection': 1,\n",
       "         'daytime': 1,\n",
       "         'course': 1,\n",
       "         'assistance': 4,\n",
       "         'amended': 1,\n",
       "         'throughout': 2,\n",
       "         'ohio': 1,\n",
       "         'commercial': 1,\n",
       "         'processes': 1,\n",
       "         'open': 1,\n",
       "         'growth': 2,\n",
       "         'plants': 1,\n",
       "         'had': 4,\n",
       "         'clear': 1,\n",
       "         'increase': 3,\n",
       "         'standard': 2,\n",
       "         'countries': 3,\n",
       "         'house': 2,\n",
       "         'allowed': 1,\n",
       "         'been': 8,\n",
       "         '3': 4,\n",
       "         '1952': 1,\n",
       "         'claims': 2,\n",
       "         'portion': 1,\n",
       "         'faculty': 3,\n",
       "         'today': 2,\n",
       "         'high': 2,\n",
       "         'continues': 1,\n",
       "         'most': 4,\n",
       "         'shown': 2,\n",
       "         'are': 21,\n",
       "         'resources': 2,\n",
       "         'plan': 3,\n",
       "         'men': 3,\n",
       "         'action': 3,\n",
       "         'sense': 1,\n",
       "         'scientific': 1,\n",
       "         '50': 1,\n",
       "         'member': 1,\n",
       "         'they': 8,\n",
       "         'club': 1,\n",
       "         '(': 18,\n",
       "         'education': 1,\n",
       "         'report': 4,\n",
       "         'physical': 1,\n",
       "         'types': 2,\n",
       "         'second': 1,\n",
       "         'own': 3,\n",
       "         'university': 2,\n",
       "         'added': 1,\n",
       "         'september': 1,\n",
       "         'addition': 2,\n",
       "         'page': 1,\n",
       "         'units': 1,\n",
       "         'developed': 3,\n",
       "         'science': 1,\n",
       "         'purchase': 2,\n",
       "         'radio': 2,\n",
       "         'would': 8,\n",
       "         'college': 3,\n",
       "         'corps': 4,\n",
       "         'otherwise': 2,\n",
       "         'beyond': 1,\n",
       "         'disease': 1,\n",
       "         'but': 8,\n",
       "         'total': 3,\n",
       "         'completion': 1,\n",
       "         'a.': 2,\n",
       "         'concerning': 1,\n",
       "         'living': 1,\n",
       "         'themselves': 2,\n",
       "         'cover': 1,\n",
       "         'missile': 1,\n",
       "         'was': 13,\n",
       "         'b': 3,\n",
       "         'cars': 2,\n",
       "         'brown': 4,\n",
       "         'knowledge': 1,\n",
       "         'final': 1,\n",
       "         'states': 11,\n",
       "         'effective': 2,\n",
       "         'fields': 1,\n",
       "         'hours': 2,\n",
       "         'devoted': 1,\n",
       "         'president': 4,\n",
       "         'up': 3,\n",
       "         'war': 1,\n",
       "         'loan': 2,\n",
       "         'officer': 2,\n",
       "         'virgin': 1,\n",
       "         'allotment': 3,\n",
       "         'taxes': 1,\n",
       "         'point': 2,\n",
       "         'alone': 1,\n",
       "         'research': 4,\n",
       "         'income': 4,\n",
       "         'industrial': 3,\n",
       "         'consider': 1,\n",
       "         'carleton': 2,\n",
       "         'transportation': 1,\n",
       "         'base': 1,\n",
       "         'central': 2,\n",
       "         'attention': 2,\n",
       "         'projects': 4,\n",
       "         'encourage': 1,\n",
       "         'precision': 1,\n",
       "         'only': 5,\n",
       "         'applied': 1,\n",
       "         'board': 5,\n",
       "         '31': 2,\n",
       "         'and': 68,\n",
       "         'directed': 1,\n",
       "         'ballet': 1,\n",
       "         'approximately': 1,\n",
       "         'reduce': 1,\n",
       "         'fallout': 1,\n",
       "         'come': 1,\n",
       "         'essential': 1,\n",
       "         'began': 1,\n",
       "         'prevent': 1,\n",
       "         'institution': 1,\n",
       "         'trained': 1,\n",
       "         'forth': 1,\n",
       "         'return': 3,\n",
       "         'obtained': 2,\n",
       "         'objectives': 1,\n",
       "         'hundred': 2,\n",
       "         'possible': 2,\n",
       "         'likely': 1,\n",
       "         'shares': 1,\n",
       "         'many': 6,\n",
       "         'foundation': 1,\n",
       "         'or': 20,\n",
       "         'funds': 3,\n",
       "         'liquid': 1,\n",
       "         'fall': 1,\n",
       "         'hawaii': 1,\n",
       "         'recently': 1,\n",
       "         'date': 2,\n",
       "         'court': 2,\n",
       "         'activities': 3,\n",
       "         'administrative': 2,\n",
       "         'radiation': 1,\n",
       "         'studies': 2,\n",
       "         'purpose': 2,\n",
       "         'reasons': 1,\n",
       "         'laboratory': 1,\n",
       "         'granted': 1,\n",
       "         '10': 2,\n",
       "         'mile': 1,\n",
       "         'fully': 1,\n",
       "         'services': 4,\n",
       "         'transition': 1,\n",
       "         'district': 2,\n",
       "         \"state's\": 2,\n",
       "         'job': 1,\n",
       "         'increases': 1,\n",
       "         'delaware': 1,\n",
       "         'beginning': 1,\n",
       "         'provide': 4,\n",
       "         'refund': 1,\n",
       "         'filed': 1,\n",
       "         'improved': 1,\n",
       "         'life': 1,\n",
       "         'carrying': 1,\n",
       "         'bank': 2,\n",
       "         'large': 3,\n",
       "         'included': 1,\n",
       "         'good': 2,\n",
       "         'years': 7,\n",
       "         'certain': 2,\n",
       "         'purchases': 1,\n",
       "         'determination': 1,\n",
       "         'state': 12,\n",
       "         'nine': 1,\n",
       "         'organization': 1,\n",
       "         'islands': 1,\n",
       "         'interests': 1,\n",
       "         'policy': 4,\n",
       "         'fiscal': 7,\n",
       "         'revenue': 1,\n",
       "         'million': 4,\n",
       "         'strength': 1,\n",
       "         'short': 1,\n",
       "         'issue': 1,\n",
       "         'later': 2,\n",
       "         'bulletin': 1,\n",
       "         'located': 1,\n",
       "         ')': 18,\n",
       "         'engineering': 1,\n",
       "         \"foundation's\": 1,\n",
       "         'paid': 2,\n",
       "         'will': 14,\n",
       "         'testimony': 1,\n",
       "         'treasury': 2,\n",
       "         'great': 4,\n",
       "         'economic': 3,\n",
       "         'be': 28,\n",
       "         'evaluation': 1,\n",
       "         'able': 1,\n",
       "         'provisions': 2,\n",
       "         'o.': 1,\n",
       "         'important': 4,\n",
       "         'considered': 1,\n",
       "         'percentage': 1,\n",
       "         'problem': 3,\n",
       "         'agencies': 2,\n",
       "         'per': 4,\n",
       "         'lands': 1,\n",
       "         'operating': 2,\n",
       "         'legislative': 1,\n",
       "         'notes': 1,\n",
       "         'prior': 2,\n",
       "         'major': 2,\n",
       "         'like': 2,\n",
       "         'him': 2,\n",
       "         'cost': 3,\n",
       "         'than': 8,\n",
       "         'directly': 1,\n",
       "         'designed': 2,\n",
       "         'whereof': 1,\n",
       "         'wildlife': 1,\n",
       "         'shall': 7,\n",
       "         'stock': 2,\n",
       "         'du': 3,\n",
       "         'conducted': 1,\n",
       "         'considerable': 1,\n",
       "         'r.': 1,\n",
       "         'four': 1,\n",
       "         'expansion': 1,\n",
       "         'unadjusted': 1,\n",
       "         'served': 1,\n",
       "         'with': 19,\n",
       "         'training': 2,\n",
       "         'local': 4,\n",
       "         'largely': 1,\n",
       "         'best': 2,\n",
       "         'add': 1,\n",
       "         'some': 5,\n",
       "         '5': 2,\n",
       "         'evidence': 1,\n",
       "         'circumstances': 1,\n",
       "         'forest': 2,\n",
       "         'taken': 1,\n",
       "         'held': 2,\n",
       "         'two': 5,\n",
       "         'complete': 1,\n",
       "         'india': 2,\n",
       "         'objective': 1,\n",
       "         'same': 4,\n",
       "         'january': 1,\n",
       "         'go': 1,\n",
       "         'manufacturers': 1,\n",
       "         'wall': 1,\n",
       "         'people': 2,\n",
       "         'specified': 1,\n",
       "         'west': 1,\n",
       "         'organizations': 2,\n",
       "         'citizens': 1,\n",
       "         'difference': 1,\n",
       "         'religious': 1,\n",
       "         'situated': 1,\n",
       "         'toward': 2,\n",
       "         'also': 6,\n",
       "         'america': 3,\n",
       "         'whole': 2,\n",
       "         'financing': 2,\n",
       "         'standards': 2,\n",
       "         'them': 5,\n",
       "         'april': 2,\n",
       "         'however': 3,\n",
       "         'motors': 3,\n",
       "         'deductions': 1,\n",
       "         'personal': 3,\n",
       "         'well': 3,\n",
       "         'continued': 1,\n",
       "         'shelters': 1,\n",
       "         'indicated': 1,\n",
       "         'higher': 1,\n",
       "         'materials': 1,\n",
       "         \"''\": 8,\n",
       "         \"pont's\": 1,\n",
       "         'participation': 1,\n",
       "         'station': 1,\n",
       "         'situation': 1,\n",
       "         'next': 1,\n",
       "         'concerned': 1,\n",
       "         'keep': 1,\n",
       "         'get': 1,\n",
       "         'movable': 1,\n",
       "         'here': 2,\n",
       "         'automobile': 1,\n",
       "         'level': 2,\n",
       "         'respect': 3,\n",
       "         'policies': 2,\n",
       "         'among': 2,\n",
       "         'usually': 1,\n",
       "         'company': 2,\n",
       "         'series': 1,\n",
       "         'young': 1,\n",
       "         'agency': 2,\n",
       "         'covered': 1,\n",
       "         'commerce': 2,\n",
       "         'annual': 2,\n",
       "         'uniform': 2,\n",
       "         'month': 2,\n",
       "         'even': 3,\n",
       "         'emergency': 1,\n",
       "         'do': 4,\n",
       "         'representative': 1,\n",
       "         'completed': 1,\n",
       "         'amounts': 1,\n",
       "         'nation': 2,\n",
       "         'assure': 1,\n",
       "         'expected': 1,\n",
       "         'way': 2,\n",
       "         'machines': 2,\n",
       "         'medical': 4,\n",
       "         'there': 7,\n",
       "         'less': 3,\n",
       "         'below': 2,\n",
       "         'no': 5,\n",
       "         'unit': 1,\n",
       "         'manufacturing': 1,\n",
       "         'new': 9,\n",
       "         ...})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Does the same thing as above.\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "# Pick values from the table that we create before.\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.size(0)\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):\n",
    "        nsample = []\n",
    "        target_index = targets[i].item()\n",
    "        while len(nsample) < k: # num of sampling\n",
    "            neg = random.choice(unigram_table)\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
    "    \n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2360, 2632, 5264],\n",
       "        [1588, 1038, 3646],\n",
       "        [6830, 3346, 4873],\n",
       "        [1961, 1145, 5341],\n",
       "        [ 302, 2632,  656],\n",
       "        [7146, 4770, 1684],\n",
       "        [7235, 3688,    1],\n",
       "        [5372, 4298,  213],\n",
       "        [ 960, 6166, 1213],\n",
       "        [ 190, 6106,  518]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "num_neg = 3\n",
    "negative_sampling(target_batch, unigram_table, num_neg)\n",
    "\n",
    "#{'grapes': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'ice': 4, 'orange': 5, 'dog': 6, 'monkey': 7, 'conda': 8, 'fruit': 9, 'banana': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNegSampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(SkipgramNegSampling, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "                    \n",
    "    def forward(self, center_words, target_words, negative_words):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
    "        \n",
    "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        negative_score = torch.sum(neg_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2), 1).view(neg_embeds.size(0), -1) # BxK -> Bx1\n",
    "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1] = [batch_size, k] ==sum==> [batch_size, 1]\n",
    "        \n",
    "        # This is what had been changed from the normal one.\n",
    "        loss = self.logsigmoid(positive_score) + self.logsigmoid(negative_score)\n",
    "        \n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameter\n",
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 100 #so we can later plot\n",
    "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
    "num_neg        = 10 # num of negative sampling\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | cost: 12.248115 | time: 0m 0s\n",
      "Epoch: 200 | cost: 16.505119 | time: 0m 0s\n",
      "Epoch: 300 | cost: 11.288136 | time: 0m 0s\n",
      "Epoch: 400 | cost: 21.915285 | time: 0m 0s\n",
      "Epoch: 500 | cost: 14.339628 | time: 0m 0s\n",
      "Total time use in negative sampling 2 miniute(s) 8 second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    input_batch, target_batch = random_batch(batch_size, corpus, 2)\n",
    "\n",
    "    # Neat trick to avoid nd.array object (This is bad practice!)\n",
    "    input_batch = list(input_batch)\n",
    "\n",
    "    # Padding since we do not cut the sentence so, It will not be in the same shape sometimes.\n",
    "    lenght_batch0 = len(input_batch[0])\n",
    "    lenght_batch1 = len(input_batch[1])\n",
    "    pad_num = np.abs(lenght_batch0 - lenght_batch1)\n",
    "\n",
    "    # pad the zero dimension\n",
    "    if lenght_batch0 < lenght_batch1:\n",
    "        input_batch[0].extend(list(np.full((pad_num, ), 0))) # Padding with zero\n",
    "    # pad the first dimension\n",
    "    elif lenght_batch0 > lenght_batch1:\n",
    "        input_batch[1].extend(list(np.full((pad_num, ), 0)))\n",
    "\n",
    "    \n",
    "    #input_batch: [batch_size, 1]\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    \n",
    "    #target_batch: [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch)\n",
    "    \n",
    "    #negs_batch:   [batch_size, num_neg]\n",
    "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    loss = model(input_batch, target_batch, negs_batch)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "end_train_time = time.time()\n",
    "neg_train_time_mins, neg_train_time_secs = epoch_time(start_train_time, end_train_time)\n",
    "print(f'Total time use in negative sampling {neg_train_time_mins} miniute(s) {neg_train_time_secs} second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/Neg_Skipgram.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': capital-common-countries', 'Athens Greece Baghdad Iraq', 'Athens Greece Bangkok Thailand']\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "def read_data(path):\n",
    "    file = open(path, 'r') # Dataset from amamda\n",
    "    contents = file.read()\n",
    "    contents = contents.split('\\n') # Seperate chunk of text into substring\n",
    "    file.close()\n",
    "    return contents\n",
    "\n",
    "path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/questions-words.txt'\n",
    "text = read_data(path)\n",
    "print(text[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ': capital-common-countries'),\n",
       " (507, ': capital-world'),\n",
       " (5032, ': currency'),\n",
       " (5899, ': city-in-state'),\n",
       " (8367, ': family'),\n",
       " (8874, ': gram1-adjective-to-adverb'),\n",
       " (9867, ': gram2-opposite'),\n",
       " (10680, ': gram3-comparative'),\n",
       " (12013, ': gram4-superlative'),\n",
       " (13136, ': gram5-present-participle'),\n",
       " (14193, ': gram6-nationality-adjective'),\n",
       " (15793, ': gram7-past-tense'),\n",
       " (17354, ': gram8-plural'),\n",
       " (18687, ': gram9-plural-verbs')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the seperator name and index\n",
    "seperator = [(idx, sent) for idx, sent in enumerate(text) if sent[0] == ':']\n",
    "seperator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptable unacceptable aware unaware\n",
      "woman women snake snakes\n"
     ]
    }
   ],
   "source": [
    "# Let's use opposite and plural\n",
    "opposite = text[9868:10680]\n",
    "plural = text[17355:18687]\n",
    "\n",
    "# Concatenate\n",
    "test_text = opposite + plural\n",
    "\n",
    "# Checking\n",
    "print(test_text[0])\n",
    "print(test_text[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['acceptable', 'unacceptable', 'aware', 'unaware'], ['acceptable', 'unacceptable', 'certain', 'uncertain'], ['acceptable', 'unacceptable', 'clear', 'unclear'], ['acceptable', 'unacceptable', 'comfortable', 'uncomfortable'], ['acceptable', 'unacceptable', 'competitive', 'uncompetitive']]\n"
     ]
    }
   ],
   "source": [
    "test_opposite = [sent.split(\" \") for sent in opposite]\n",
    "test_plural = [sent.split(\" \") for sent in plural]\n",
    "test_corpus = [sent.split(\" \") for sent in test_text]\n",
    "print(test_corpus[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impossibly', 'computer', 'elephants', 'pears', 'irrational']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten and get Unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "test_vocab = list(set(flatten(test_corpus)))\n",
    "test_vocab[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "# Word2index and Index2word for test set\n",
    "# Word2index and Index2word\n",
    "\n",
    "# assign id to those vocabs\n",
    "test_word2index = dict()\n",
    "test_word2index.update({\"<UNK>\":  0})\n",
    "for idx, v in enumerate(test_vocab):\n",
    "        test_word2index.update({v:  idx + 1})\n",
    "\n",
    "#add <UNK>, which is a very normal token exists in the world\n",
    "test_vocab.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything\n",
    "\n",
    "# Testing\n",
    "print(test_word2index['car'])\n",
    "\n",
    "# index2word\n",
    "test_index2word = {v:k for k, v in test_word2index.items()}\n",
    "\n",
    "print(test_index2word[test_word2index['car']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embedding\n",
    "def get_embed(word, current_model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
    "    return np.array(embed[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put it in a loop soon!\n",
    "models_weight_list = ['GloVe', 'CBOW', 'Skipgram', 'Neg_Skipgram']\n",
    "model_list = [GloVe(voc_size, embedding_size), \n",
    "              GloVe(voc_size, embedding_size), \n",
    "              Cbow(voc_size, embedding_size), \n",
    "              Skipgram(voc_size, embedding_size), \n",
    "              SkipgramNegSampling(voc_size, embedding_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7981735 ,  0.3838179 , -0.36671826, -0.48267865,  0.26179492,\n",
       "       -0.3489858 , -0.08714995, -0.38581833,  1.6609585 , -0.5792571 ,\n",
       "       -0.52467054,  0.2776766 ,  0.47701734, -0.3608383 , -0.3687769 ,\n",
       "        0.32260102, -0.47021452,  1.5255069 , -0.43845403, -0.6355107 ,\n",
       "        0.99704975, -0.5858865 , -0.8325716 ,  0.14871874, -0.58258206,\n",
       "        0.9743253 ,  0.38821566,  0.7867026 , -0.538668  , -0.81857187,\n",
       "        0.16740286, -0.6317246 , -0.21795206, -0.07072954, -1.1923411 ,\n",
       "        1.0391904 , -0.65810436, -0.8414976 , -1.2894249 ,  0.59089243,\n",
       "        0.40816256, -0.02337929, -0.8058307 ,  0.5699825 , -0.25628445,\n",
       "        0.26372465,  0.7058599 ,  1.1191238 , -0.1993269 , -0.7629969 ,\n",
       "       -0.3672024 , -0.76915467, -0.30962247, -0.02698094,  0.15500481,\n",
       "        0.7073642 , -0.7914547 ,  0.38551423, -0.971647  ,  0.29007387,\n",
       "        0.06968477, -0.81958306,  1.0259353 , -0.7165971 ,  0.33586895,\n",
       "       -0.52778935, -0.36265248, -0.7546539 , -0.694041  , -0.247558  ,\n",
       "        0.4426221 ,  0.11594248, -0.47466955,  0.358508  , -0.49659678,\n",
       "       -0.94471043, -1.0588918 ,  0.6589844 ,  0.96659124, -1.794116  ,\n",
       "        1.4310553 ,  0.9184189 ,  0.1455431 ,  0.14560351,  1.0645146 ,\n",
       "       -0.13142255, -0.73518133, -0.69743025, -0.11359148, -0.42046416,\n",
       "        0.23863298,  0.51225746,  0.7210246 , -0.3381745 , -0.21456823,\n",
       "       -0.24725914,  0.16126153,  0.748523  , -0.45502418,  0.22046515],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test embeded\n",
    "testing_word = 'Queen'\n",
    "current_model = model_list[0]\n",
    "\n",
    "weight_path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/GloVe.pth'\n",
    "\n",
    "current_weight = models_weight_list[0]\n",
    "current_model.load_state_dict(torch.load(weight_path))\n",
    "current_model.eval()\n",
    "\n",
    "test_embed = get_embed(testing_word, current_model)\n",
    "test_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(a,b,c,vocabs=vocab):\n",
    "    emb_a, emb_b, emb_c = get_embed(a, current_model), get_embed(b, current_model), get_embed(c, current_model)\n",
    "    vector = emb_b - emb_a + emb_c\n",
    "    # vector_norm = (vector ** 2).sum() ** (1 / 2)\n",
    "    # vector = vector / vector_norm\n",
    "    # print(vector.shape)\n",
    "    similarity = -1 \n",
    "    \n",
    "    for vocab in vocabs:\n",
    "        if vocab not in [a,b,c]: #ignore input words itself\n",
    "            current_sim = cos_sim(vector,get_embed(vocab, current_model))\n",
    "            if current_sim > similarity:\n",
    "                similarity = current_sim #update better one\n",
    "                d = (vocab, similarity)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('specifications', 0.37618497)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing find_analogy functions\n",
    "find_analogy('man', 'woman', 'adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'specifications'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_analogy('man', 'woman', 'adult')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Semantic testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put it in a loop soon!\n",
    "models_weight_list = ['GloVe', 'CBOW', 'Skipgram', 'Neg_Skipgram']\n",
    "models_name = ['Glove', 'Cbow', 'Skipgram', 'Neg_Skipgram']\n",
    "voc_size = len(vocab)\n",
    "embedding_size = 100\n",
    "model_list = [GloVe(voc_size, embedding_size), \n",
    "              GloVe(voc_size, embedding_size), \n",
    "              Cbow(voc_size, embedding_size), \n",
    "              Skipgram(voc_size, embedding_size), \n",
    "              SkipgramNegSampling(voc_size, embedding_size)]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "test_list = [test_opposite, test_plural]\n",
    "test_list_name = ['test_opposite', 'test_plural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accruacy(y, yhat):\n",
    "    if y == yhat:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def test_accruacy_batch(data, current_model):\n",
    "    counter = 0\n",
    "    for sent in data:\n",
    "        label = sent[-1]\n",
    "        a, b, c = sent[:-1]\n",
    "        yhat = find_analogy(a, b, c)[0] # It's return in tuple form, so we need to slice to get word\n",
    "        if check_accruacy(label, yhat) == True:\n",
    "            counter = counter + 1\n",
    "    \n",
    "    return counter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model = Glove\n",
      "Current weight = GloVe\n",
      "Current_test = test_opposite\n",
      "0\n",
      "Current_test = test_plural\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GloVe:\n\tMissing key(s) in state_dict: \"v_bias.weight\", \"u_bias.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/GloVe_assg.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sapnathapa/Documents/AIT/Spring%20Sem%202023/NLP/GloVe/GloVe_assg.ipynb#Y141sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m weight_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m models_weight_list[models_idx] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sapnathapa/Documents/AIT/Spring%20Sem%202023/NLP/GloVe/GloVe_assg.ipynb#Y141sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m current_model \u001b[39m=\u001b[39m model_list[models_idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sapnathapa/Documents/AIT/Spring%20Sem%202023/NLP/GloVe/GloVe_assg.ipynb#Y141sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m current_model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(weight_path))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sapnathapa/Documents/AIT/Spring%20Sem%202023/NLP/GloVe/GloVe_assg.ipynb#Y141sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m current_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sapnathapa/Documents/AIT/Spring%20Sem%202023/NLP/GloVe/GloVe_assg.ipynb#Y141sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCurrent model = \u001b[39m\u001b[39m{\u001b[39;00mmodels_name[models_idx]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GloVe:\n\tMissing key(s) in state_dict: \"v_bias.weight\", \"u_bias.weight\". "
     ]
    }
   ],
   "source": [
    "\n",
    "main_results = list()\n",
    "main_accruacy = list()\n",
    "main_results_name = list()\n",
    "results = list()\n",
    "accruacy = list()\n",
    "results_name = list()\n",
    "\n",
    "for models_idx in range(len(models_weight_list)):\n",
    "    weight_path = '/Users/sapnathapa/Documents/AIT/Spring Sem 2023/NLP/GloVe/' + models_weight_list[models_idx] + '.pth'\n",
    "    current_model = model_list[models_idx]\n",
    "    current_model.load_state_dict(torch.load(weight_path))\n",
    "    current_model.eval()\n",
    "    print(f'Current model = {models_name[models_idx]}')\n",
    "    print(f'Current weight = {models_weight_list[models_idx]}')\n",
    "    \n",
    "    for idx, current_test in enumerate(test_list):\n",
    "        sample_list = random.choices(current_test, k=100)\n",
    "        print(f'Current_test = {test_list_name[idx]}')\n",
    "        accruacy = test_accruacy_batch(sample_list, current_model)\n",
    "        print(accruacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
